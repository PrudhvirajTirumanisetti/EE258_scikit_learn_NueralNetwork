{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prudhviraj Tirumanisetti \n",
    "EE 258 ID: 011489881"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "In this assignment, you'll explore linear regression and logistic regression, the perceptron, and support vector machines: popular approaches which share a similar form of producing output in the form of a weighted combination of attributes, but with very different approaches to learning the underyling model. The assignment explores two of the general data mining tasks: regression and classification, and takes a closer look at multiclass classification with these techniques. \n",
    "\n",
    "Similar to previous assignments, you're expected to respond to each question with your answer in a Markdown cell and clearly labeled code supporting your answer in a code cell. When you submit the assignment, you should upload the two notebooks (`.ipynb` files) corresponding to your solutions and also generate a PDF of each notebook that includes the answers, code, and all intermediate output. In total, you will submit four files: two notebooks and two PDFs generated from those notebooks. This assignment is due on 10/16/17 at 11:59pm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Linear and Logistic Regression, Perceptrons (40 points)\n",
    "We'll start by looking at a simple example of linear regression. As with many of the other data mining algorithms we've encountered, we'll be using the implementation available in the `linear_model` module of scikit-learn. Now would be a good time to go read the [documentation](http://scikit-learn.org/stable/modules/linear_model.html) on linear models and refresh your memory on the high-level ideas. Once you've done that, we'll go through a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preliminaries\n",
    "\n",
    "#Show plots in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import datasets, preprocessing, cross_validation, feature_extraction\n",
    "from sklearn import linear_model, svm, metrics, ensemble\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib2\n",
    "\n",
    "# Helper functions\n",
    "def folds_to_split(data,targets,train,test):\n",
    "    data_tr = pd.DataFrame(data).iloc[train]\n",
    "    data_te = pd.DataFrame(data).iloc[test]\n",
    "    labels_tr = pd.DataFrame(targets).iloc[train]\n",
    "    labels_te = pd.DataFrame(targets).iloc[test]\n",
    "    return [data_tr, data_te, labels_tr, labels_te]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression on the Diabetes Dataset\n",
    "The first dataset we'll explore is the [Diabetes dataset](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes), one of the pre-packaged datasets available in scikit-learn. There aren't too many details about this dataset out there, but the common description is that it contains 10 physiological variables (age, sex, weight, blood pressure) for 442 patients, and the target is an indication of disease progression after one year. Like any good data miners, let's poke around and check out the data before we get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 10)\n",
      "                  0             1             2             3             4  \\\n",
      "count  4.420000e+02  4.420000e+02  4.420000e+02  4.420000e+02  4.420000e+02   \n",
      "mean  -3.634285e-16  1.308343e-16 -8.045349e-16  1.281655e-16 -8.835316e-17   \n",
      "std    4.761905e-02  4.761905e-02  4.761905e-02  4.761905e-02  4.761905e-02   \n",
      "min   -1.072256e-01 -4.464164e-02 -9.027530e-02 -1.123996e-01 -1.267807e-01   \n",
      "25%   -3.729927e-02 -4.464164e-02 -3.422907e-02 -3.665645e-02 -3.424784e-02   \n",
      "50%    5.383060e-03 -4.464164e-02 -7.283766e-03 -5.670611e-03 -4.320866e-03   \n",
      "75%    3.807591e-02  5.068012e-02  3.124802e-02  3.564384e-02  2.835801e-02   \n",
      "max    1.107267e-01  5.068012e-02  1.705552e-01  1.320442e-01  1.539137e-01   \n",
      "\n",
      "                  5             6             7             8             9  \n",
      "count  4.420000e+02  4.420000e+02  4.420000e+02  4.420000e+02  4.420000e+02  \n",
      "mean   1.327024e-16 -4.574646e-16  3.777301e-16 -3.830854e-16 -3.412882e-16  \n",
      "std    4.761905e-02  4.761905e-02  4.761905e-02  4.761905e-02  4.761905e-02  \n",
      "min   -1.156131e-01 -1.023071e-01 -7.639450e-02 -1.260974e-01 -1.377672e-01  \n",
      "25%   -3.035840e-02 -3.511716e-02 -3.949338e-02 -3.324879e-02 -3.317903e-02  \n",
      "50%   -3.819065e-03 -6.584468e-03 -2.592262e-03 -1.947634e-03 -1.077698e-03  \n",
      "75%    2.984439e-02  2.931150e-02  3.430886e-02  3.243323e-02  2.791705e-02  \n",
      "max    1.987880e-01  1.811791e-01  1.852344e-01  1.335990e-01  1.356118e-01  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/viktorjankov/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:17: FutureWarning: \n",
      "The default value for 'return_type' will change to 'axes' in a future release.\n",
      " To use the future behavior now, set return_type='axes'.\n",
      " To keep the previous behavior and silence this warning, set return_type='dict'.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEKCAYAAADpfBXhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nm5ktIBd3M7MF9P8BoEhNYUB72y4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a095a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEACAYAAABbMHZzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzl8IIWqIOn8hhKgh6vyFEKKG/H99ojtYIfBkcAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1090be550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the data\n",
    "diabetes = datasets.load_diabetes();\n",
    "# Put it into pandas DataFrames\n",
    "diabetes_data_df = pd.DataFrame(diabetes.data);\n",
    "diabetes_target_df = pd.DataFrame(diabetes.target)\n",
    "\n",
    "# How many attributes and records are there?\n",
    "print diabetes_data_df.shape\n",
    "\n",
    "# What are the descriptive statistics?\n",
    "print diabetes_data_df.describe()\n",
    "# How are the labels distributed?\n",
    "diabetes_target_df.hist()\n",
    "\n",
    "# How are the attributes distributed?\n",
    "plt.figure()\n",
    "axes = diabetes_data_df.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice anything interesting about the data? The attributes have been normalized - each has a similar mean and standard deviation. Now let's train our first regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2:\t0.533716155537\n",
      "[ 124.87699265  241.04779116  239.55002222  262.61331893  245.76075935\n",
      "  215.38130957   98.25024738  167.10341193   86.15467868  149.23130648\n",
      "  139.44688429  121.07843815  145.93392542  113.89242688  137.00001959\n",
      "  106.07596308  188.8720697   151.64642212  147.17548161  193.9762092\n",
      "  193.24395545  123.38347892  244.93128416  221.35017651   73.23177137\n",
      "  175.0689274   270.81318019   76.43093304  147.64128689  106.93226173\n",
      "   72.18329933  246.22062792  155.49372733  132.93631466  122.1416297\n",
      "   70.14373998  182.1432308   259.16039335  119.69523429  217.32224665\n",
      "  156.87184212  209.45289148  152.68147644   97.91484124   99.47991166\n",
      "   60.35999351  163.47427462  175.63241326  165.73475646  120.17137496\n",
      "  143.1380446    65.50402188  161.25927147  165.59617116  127.56318762\n",
      "  145.47983532  119.2772516   140.89228502  138.44957973  234.27031641\n",
      "   70.42410076  219.75216763   96.49453974  169.97467564   75.49176572\n",
      "  141.43569069  146.08650475   97.22882088  235.72934302  115.60626381\n",
      "  140.86586191   83.8398695   226.79822353  232.14151232  153.56934861\n",
      "   85.00662969  185.94162205  100.59978839   80.74525585  160.50153247\n",
      "  136.07622533  111.57342257  150.66490274  181.52512021  203.54463809\n",
      "  205.67406873  142.71143086  127.42691032  139.56003045  151.35437113\n",
      "  242.54261548  206.12199133  145.09312121  120.10821335  248.91044186\n",
      "  177.46641126  145.28356072   79.89910472  155.73208421  113.43239324\n",
      "  162.18337986   99.99524699  191.84896583  154.24943403  166.81908955\n",
      "  104.90171597  220.98892005  134.51002344   38.0086503   203.29399974\n",
      "  181.12997599]\n",
      "MSE:\t2919.42264017\n",
      "[  11.18121228 -219.22917848  492.74550531  360.62854712 -880.75696356\n",
      "  560.47207888  138.68964051  208.07342467  723.26859805   47.00741834]\n"
     ]
    }
   ],
   "source": [
    "# First we'll do a simple train-test split:\n",
    "[dbt_tr_data, dbt_te_data,\n",
    " dbt_tr_target, dbt_te_target] = cross_validation.train_test_split(diabetes.data,diabetes.target, random_state=20160202)\n",
    "\n",
    "# Create the LinearRegression classifier\n",
    "lr = linear_model.LinearRegression()\n",
    "\n",
    "# Learn the linear regression model\n",
    "lr.fit(dbt_tr_data, dbt_tr_target)\n",
    "\n",
    "# Print out the coefficient of determination (R^2)\n",
    "print \"R^2:\\t\",lr.score(dbt_te_data,dbt_te_target)\n",
    "\n",
    "# Peek at the predictions\n",
    "dbt_te_predict = lr.predict(dbt_te_data)\n",
    "print dbt_te_predict\n",
    "\n",
    "# And also the mean squared error:\n",
    "print \"MSE:\\t\", metrics.mean_squared_error(dbt_te_target, dbt_te_predict)\n",
    "\n",
    "# Which attributes were important to this prediction? We can find out by looking at the attribute weights:\n",
    "print lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully you can see the similarities between how to build a [LinearRegression model](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression) and the previous assignment on DecisionTrees.  The big difference is that the predictions are not classes, but continuous values (much like the training targets). One consequence is that we can't use the same metrics for regression and classification. One metric that we've discussed (and that linear regression attempts to minimize directly) is the [mean squared error](https://en.wikipedia.org/wiki/Mean_squared_error) or MSE. If you understand how the MSE works, the leap to the default metric that regression reports (via the `.score()` function) -- the [coefficient of determination](https://en.wikipedia.org/wiki/Coefficient_of_determination) (R^2) -- shouldn't be too hard to understand. Read about the R^2 metric and make sure you understand what it measures.\n",
    "\n",
    "The above example used a simple train-test split, but we can be more confident of our conclusions if we perform cross-validation. Let's use cross-validation to experiment with the same dataset and take a look at the results. Note that this example provides you with some tricks that you might have missed in the last assignment, so understanding the code below and learning to use it should be helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\t\t R^2 metric = 0.556 \t\t MSE = 2533.8 \n",
      "Fold 2\t\t R^2 metric = 0.231 \t\t MSE = 2870.8 \n",
      "Fold 3\t\t R^2 metric = 0.354 \t\t MSE = 3512.7 \n",
      "Fold 4\t\t R^2 metric = 0.622 \t\t MSE = 2759.2 \n",
      "Fold 5\t\t R^2 metric = 0.266 \t\t MSE = 3555.7 \n",
      "Fold 6\t\t R^2 metric = 0.618 \t\t MSE = 2900.4 \n",
      "Fold 7\t\t R^2 metric = 0.418 \t\t MSE = 3696.3 \n",
      "Fold 8\t\t R^2 metric = 0.435 \t\t MSE = 2282.3 \n",
      "Fold 9\t\t R^2 metric = 0.434 \t\t MSE = 4122.9 \n",
      "Fold 10\t\t R^2 metric = 0.686 \t\t MSE = 1769.7 \n",
      "         R^2          MSE\n",
      "1   0.556144  2533.848109\n",
      "2   0.230561  2870.767711\n",
      "3   0.353578  3512.723509\n",
      "4   0.621905  2759.227129\n",
      "5   0.265876  3555.677943\n",
      "6   0.618193  2900.380412\n",
      "7   0.418159  3696.281878\n",
      "8   0.435152  2282.279598\n",
      "9   0.434370  4122.939981\n",
      "10  0.685685  1769.684057\n",
      "R^2       0.461962\n",
      "MSE    3000.381033\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "foldnum = 0\n",
    "fold_results = pd.DataFrame()\n",
    "for train, test in cross_validation.KFold(len(diabetes.data), n_folds=10):\n",
    "    foldnum+=1\n",
    "    [dbt_tr_data, dbt_te_data,\n",
    "     dbt_tr_target, dbt_te_target] = folds_to_split(diabetes.data,diabetes.target,train,test)\n",
    "\n",
    "    lr = linear_model.LinearRegression()\n",
    "    lr.fit(dbt_tr_data, dbt_tr_target)\n",
    "    # We could print out our results\n",
    "    print \"Fold %d\\t\\t R^2 metric = %03.3f \\t\\t MSE = %03.1f \" % (foldnum,  \n",
    "                                                                  lr.score(dbt_te_data,dbt_te_target), \n",
    "                                                                  metrics.mean_squared_error(dbt_te_target, \n",
    "                                                                                             lr.predict(dbt_te_data))\n",
    "                                                                 )\n",
    "    # But a nicer way to store them is in a DataFrame\n",
    "    fold_results.loc[foldnum, 'R^2'] = lr.score(dbt_te_data, dbt_te_target)\n",
    "    fold_results.loc[foldnum, 'MSE'] = metrics.mean_squared_error(dbt_te_target, lr.predict(dbt_te_data))\n",
    "\n",
    "    # By the way, if you were searching over parameters in an inner for loop, \n",
    "    # you could store those in your results DataFrame just as easily, for example:\n",
    "    # for param in params.keys():\n",
    "    #    for paramVal in params[param]:\n",
    "    #        paramDict={}; \n",
    "    #        paramDict[param]=paramVal\n",
    "    #        dtree = tree.DecisionTreeClassifier(random_state=20160121, **paramDict)\n",
    "    #        dtree.fit(mushroom_train,mushroom_train_labels)\n",
    "    #        fold_results.loc[foldnum,'%s=%s' % (param, paramVal)]=dtree.score(mushroom_val,mushroom_val_labels)\n",
    "    \n",
    "#Now let's look at the results:\n",
    "print fold_results\n",
    "#And compute the mean error across folds:\n",
    "print fold_results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Linear Regression, Ridge Regression and Lasso (20 points)\n",
    "Now it's your turn to perform a linear regression experiment! Use the [Boston Housing Prices Dataset](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html#sklearn.datasets.load_boston) built into scikit-learn to better understand regression. You can load it with `datasets.load_boston()` and use the `.DESCR` field to learn more about the dataset.\n",
    "1.   Perform exploratory data analysis on the Boston Housing data.\n",
    "    * From your exploratory data analysis, what do you notice about the attribute values? \n",
    "    * Which parameter to the `LinearRegression` model could you use to deal with this issue? \n",
    "    * Perform 10-fold cross-validation (with `shuffle=True` and `random_state=20160202`) with a `LinearRegression` model that uses the parameter identified above. Report the average coefficient of determination and mean squared error metric on the test set (averaged across folds).\n",
    "\n",
    "2.   Two very popular options in Linear Regression are the [Lasso method](https://en.wikipedia.org/wiki/Lasso_(statistics)) and [Ridge Regression](https://en.wikipedia.org/wiki/Tikhonov_regularization). These are implemented in the [Lasso](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso) and [Ridge](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge) models in sklearn.\n",
    "   * What *one word* captures what Lasso and Ridge do? (It's in the first sentence of both Wikipedia articles and sklearn documentation pages)\n",
    "   * Perform 10-fold CV with normal `LinearRegression`, `Lasso`, and `Ridge`. Compare the attribute weights (`coef_`) of each of these methods. What do you observe? \n",
    "   * Report the average R^2 and MSE for each method on the test set across folds. How do these variants of linear regression perform?\n",
    "   \n",
    "   Hint: If you'd like to understand Ridge Regression better, you might want to look at this [example](http://scikit-learn.org/stable/auto_examples/linear_model/plot_ols_ridge_variance.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Answers 1: </h1>\n",
    "<h3>1.</h3>\n",
    "<p>\n",
    "<b>a)</b> From the exploratory data analysis, we noticed that the range of the values is huge, which is not good. For example, most of the attributes have a value below 100, while the 9th and 11th attribute have values in the hundreds. Betewen 300 and 700 for the 9th attribute [TAX] and around 400 for the 11th attribute [B] <br>\n",
    "<b>b)</b> To deal with this issue, we'll use the normalize=True parameter to the LinearRegression model<br>\n",
    "<b>c)</b> Averages: <br>\n",
    "    R^2     0.713643 <br>\n",
    "    MSE    23.657502 <br>\n",
    "\n",
    "</p>\n",
    "\n",
    "<h3>2. </h3>\n",
    "<p>\n",
    "<b>a)</b> Regularization. Both Lasso and Ridge regression are used for regularization to prevent overfitting <br>\n",
    "<b>b)</b> Looking at the attribute weights, we see several differences between the different models. <br>\n",
    "First, Lasso gets completly rid of most features, by settings the weights of 0. It only keeps 2 or 3 features in most cases as the only relevant once to predict the median house price<br>\n",
    "The Ridge regression model on the other hand, keeps most features, but we can notice that the weights are \n",
    "slightly different to the weights of the original linear regresion (i.e there are only small changes to the weights). <br>\n",
    "<br>\n",
    "<b>c)</b> <br>\n",
    "Averages: <br>\n",
    "Linear Regression:<br>\n",
    "R^2     0.713643<br>\n",
    "MSE    23.657502<br>\n",
    "<br>\n",
    "Lasso Regularization:<br>\n",
    "R^2     0.580869<br>\n",
    "MSE    35.198977<br>\n",
    "<br>\n",
    "Ridge Regression: <br>\n",
    "R^2     0.708486<br>\n",
    "MSE    24.133678<br>\n",
    "\n",
    "<br>\n",
    "TTest for LinearRegression vs RidgeRegression<br>\n",
    "Ttest_relResult(statistic=1.2154248843325626, pvalue=0.25512413165702003)<br>\n",
    "<br>\n",
    "\n",
    "TTest for Lasso vs RidgeRegression<br>\n",
    "Ttest_relResult(statistic=-9.4005571317290304, pvalue=5.9711873467613727e-06)<br>\n",
    "<br>\n",
    "\n",
    "TTest for LinearRegression vs Lasso<br>\n",
    "Ttest_relResult(statistic=8.7799598190605064, pvalue=1.0449626130453215e-05)<br>\n",
    "<br>\n",
    "\n",
    "The Lasso regression model performs significantly worse than the linear regression and the ridge regression model. This means that the model is not overfitted, and most features are relevant to predicting the median house prices. So when Lasso gets rid of some features, the model performs worse. <br> \n",
    "The Ridge regression performs slightly worse than the regular linear regression, but according to the ttest, this difference is not significant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston House Prices dataset\n",
      "\n",
      "Notes\n",
      "------\n",
      "Data Set Characteristics:  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive\n",
      "    \n",
      "    :Median Value (attribute 14) is usually the target\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "http://archive.ics.uci.edu/ml/datasets/Housing\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      "**References**\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "boston = datasets.load_boston();\n",
    "\n",
    "# Brief description of the data\n",
    "print boston.DESCR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "               0           1           2           3           4           5   \\\n",
      "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
      "mean     3.593761   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
      "std      8.596783   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
      "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
      "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
      "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
      "75%      3.647423   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
      "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
      "\n",
      "               6           7           8           9           10          11  \\\n",
      "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
      "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
      "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
      "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
      "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
      "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
      "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
      "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
      "\n",
      "               12  \n",
      "count  506.000000  \n",
      "mean    12.653063  \n",
      "std      7.141062  \n",
      "min      1.730000  \n",
      "25%      6.950000  \n",
      "50%     11.360000  \n",
      "75%     16.955000  \n",
      "max     37.970000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/viktorjankov/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:17: FutureWarning: \n",
      "The default value for 'return_type' will change to 'axes' in a future release.\n",
      " To use the future behavior now, set return_type='axes'.\n",
      " To keep the previous behavior and silence this warning, set return_type='dict'.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEKCAYAAAAcgp5RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB72Z2YzzoDczm3H/H0LLw3camtTxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10950b210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEACAYAAACj0I2EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3X+wXHWZ5/H3J8Tww2DuzY4ka6K5uEEBi507zgDWiMVl\n+TE4Q0HYpRyd2RqurltlMSnF2polzNRWkn8mhCrL4LJTW5YON7uLg5gVyFAIgTIdyyl+jaQFTchk\nBxNjNNeRhGjQkgSf/aNPN51L983t2+d09/nez6uqk3POPX2e89zb/fQ5z/nRigjMzKz85vV7BczM\nLB8u6GZmiXBBNzNLhAu6mVkiXNDNzBLhgm5mlogZFXRJn5X0PUnPS7pX0gJJw5K2Sdoj6TFJi5rm\nv13SXkm7JV1T3OqbmVmdTnUeuqR3AN8Gzo+I1yR9FXgEuBB4OSLulHQbMBwRayRdCNwLXAwsB54A\nzguf8G5mVqiZtlxOA94qaT5wJnAQuAHYnP18M7AqG74euC8iTkTEPmAvcElua2xmZi2dsqBHxI+B\nzwE/pFbIj0bEE8CSiJjM5jkEnJM9ZRlwoGkRB7NpZmZWoFMWdElD1LbGVwDvoLal/qfA1BaKWypm\nZn00fwbzXAW8FBGHASQ9APw+MClpSURMSloK/DSb/yDwzqbnL8+mnUSSPwDMzGYhItRq+kx66D8E\nPiDpDEkCrgR2AVuB8Wyem4GHsuGtwEezM2HOBVYCz7RZqY4ea9eu7fg5s3mkFCelXFKLk1IuqcUZ\n5Fymc8ot9Ih4RtIWYCdwPPv/i8DZwP2SPgHsBz6Szb9L0v1Z0T8O3BKnWosZ2rdvXx6LmVNxUsol\ntTgp5ZJanLLmMpOWCxGxHlg/ZfJhau2YVvNvADZ0t2pmZtaJUl0pOj4+7jgDGMNxBjeG4wxujCLi\nnPLCoqJIyqsTY2Y2Z0giujgoOjAqlYrjDGAMxxncGI4zuDGKiFOqgm5mZu255WJmViLJtFzMzKy9\nUhX0sva1+hknpVxSi5NSLqnFKWsupSroZmbWnnvoZmYl4h66mdkcUKqCXta+Vj/jpJRLanFSyiW1\nOGXNpVQF3czM2nMP3cysRNxDNzObA0pV0Mva1+pnnJRySS1OSrmkFqesuZSqoJuZWXvuoZuZlYh7\n6GZmc0CpCnpZ+1r9jJNSLqnFSSmX1OKUNZdTFnRJ75G0U9Jz2f9HJX1a0rCkbZL2SHpM0qKm59wu\naa+k3ZKuyXWNzcyspY566JLmAT8CLgVWAy9HxJ2SbgOGI2KNpAuBe4GLgeXAE8B5Uxvm7qGblZ/U\nspULgN/fxcizh34V8M8RcQC4AdicTd8MrMqGrwfui4gTEbEP2Atc0vFam9nAi4jGY+3aOGnceq/T\ngv7HwFey4SURMQkQEYeAc7Lpy4ADTc85mE3rWln7Wv2Mk1IuqcVJKReAsbHexPHfpr0ZF3RJb6G2\n9f21bNLUj2B/JJuZ9dH8Dub9MPCdiPhZNj4paUlETEpaCvw0m34QeGfT85Zn095kfHyckZERAIaG\nhhgdHWVsbAx445Nr6nhdu5/nMT42Nlbo8nudTy/G69MGZX3Kkk9zrKLySe313It86tMG4fVYqVSY\nmJgAaNTLdmZ8UFTS3wGPRsTmbHwjcDgiNrY5KHoptVbL4/igqJlZLro+KCrpLGoHRL/eNHkjcLWk\nPcCVwB0AEbELuB/YBTwC3JJX5Z66FVCUlOKklEtqcVLKJbU4Zc1lRi2XiPgl8PYp0w5TK/Kt5t8A\nbOh67cysNCYmoKljYX3ge7mYWS4k8Fu6eL6Xi5nZHFCqgl7WvlY/46SUS2pxUsoli9SbKP7btFWq\ngm5mZu25h25muXAPvTfcQzez3CxeXCveUx/Qevrixf1d37mkVAW9rH2tfsZJKZfU4pQ1lyNHalvi\nUx/bt1daTj9yJNfw/ttMo1QF3czM2nMP3cw60mmv3L31fLmHbmY2B5SqoJe1r9XPOCnlklqclHJJ\nLU5ZcylVQTczs/bcQzezjriH3l/uoZuZzQGlKuhl7Wv1M05KuaQWJ6VcUotT1lxKVdDNzKw999DN\nrCPuofeXe+hmZnNAqQp6Wfta/YyTUi6pxUkpl9TilDWXmX5J9CJJX5O0W9L3JV0qaVjSNkl7JD0m\naVHT/LdL2pvNf02ua2xmZi3NqIcuaQLYERH3SJoPvBX4S+DliLhT0m3AcESskXQhcC9wMbAceAI4\nb2rD3D10s3JyD72/uuqhS3ob8KGIuAcgIk5ExFHgBmBzNttmYFU2fD1wXzbfPmAvcEl3KZiZ2anM\npOVyLvAzSfdIek7SFyWdBSyJiEmAiDgEnJPNvww40PT8g9m0rpW1r9XPOCnlklqclHJJLU5Zc5k/\nw3neD/x5RPyjpM8Da4CpO1Ed71SNj48zMjICwNDQEKOjo4yNjQFvJNo8Xq1Wp/152cZ7kU9d0flU\nq9VCl59iPn49D+74IL2eK5UKExMTAI162c4pe+iSlgBPRsS7s/HLqBX0fwOMRcSkpKXA9oi4QNIa\nICJiYzb/o8DaiHh6ynLdQzcrIffQ+6urHnrWVjkg6T3ZpCuB7wNbgfFs2s3AQ9nwVuCjkhZIOhdY\nCTwz+9U3M7OZmOl56J8G7pVUBX4b+GtgI3C1pD3UivwdABGxC7gf2AU8AtyS16b41N2UoqQUJ6Vc\nUouTUi6pxSlrLjPpoRMR36V2GuJUV7WZfwOwoYv1MjOzDvleLmbWEffQ+8v3cjEzmwNKVdDL2tfq\nZ5yUckktTkq5pBanrLmUqqCbmVl77qGbWUfcQ+8v99DNzOaAUhX0sva1+hknpVxSi5NSLqnFKWsu\npSroZmbWnnvoZtYR99D7yz10M7M5oFQFvax9rX7GSSmX1OKklEtqccqaS6kKupmZteceupl1xD30\n/nIP3cxsDihVQS9rX6ufcVLKJbU4KeWSWpyy5lKqgm5mZu25h25mHXEPvb/cQzczmwNKVdDL2tfq\nZ5yUckktTkq5pBanrLnMqKBL2ifpu5J2SnommzYsaZukPZIek7Soaf7bJe2VtFvSNbmusZmZtTSj\nHrqkl4DfjYgjTdM2Ai9HxJ2SbgOGI2KNpAuBe6l9qfRy4AngvKkNc/fQzcrJPfT+yqOHrhbz3gBs\nzoY3A6uy4euB+yLiRETsA/YCl3S0xmZm1rGZFvQAHpf0rKRPZtOWRMQkQEQcAs7Jpi8DDjQ992A2\nrWtl7Wv1M05KuaQWJ6VcUotT1lzmz3C+D0bETyS9HdgmaQ+1It+s452q8fFxRkZGABgaGmJ0dJSx\nsTHgjUSbx6vV6rQ/L9t4L/KpKzqfarVa6PJTzMev58EdH6TXc6VSYWJiAqBRL9vp+Dx0SWuBY8An\ngbGImJS0FNgeERdIWgNERGzM5n8UWBsRT09ZjnvoZiXkHnp/ddVDl3SWpIXZ8FuBa4AXgK3AeDbb\nzcBD2fBW4KOSFkg6F1gJPNNVBmZmdkoz6aEvAb4taSfwFPD3EbEN2AhcnbVfrgTuAIiIXcD9wC7g\nEeCWvDbFp+6mFCWlOCnlklqclHJJLU5ZczllDz0ifgCMtph+GLiqzXM2ABu6XjszM5sx38vFzDri\nHnp/+V4uZmZzQKkKeln7Wv2Mk1IuqcVJKZfU4pQ1l1IVdDMza889dDPriHvo/eUeupnZHFCqgl7W\nvlY/46SUS2pxUsoltThlzaVUBd3MzNpzD93MOuIeen+5h25mNgeUqqCXta/Vzzgp5ZJanJRySS1O\nWXMpVUE3M7P23EM3s464h95f7qGbmc0BpSroZe1r9TNOSrmkFielXFKLU9ZcSlXQzcysPffQzawj\n7qH3l3voZmZzQKkKeln7Wv2Mk1IuqcVJKZfU4pQ1lxkXdEnzJD0naWs2Pixpm6Q9kh6TtKhp3tsl\n7ZW0W9I1ua6xmZm1NOMeuqTPAr8LvC0irpe0EXg5Iu6UdBswHBFrJF0I3AtcDCwHngDOm9owdw/d\nrJzcQ++vrnvokpYDfwh8qWnyDcDmbHgzsCobvh64LyJORMQ+YC9wySzW28zMOjDTlsvngb8Amj9n\nl0TEJEBEHALOyaYvAw40zXcwm9a1sva1+hknpVxSi5NSLqnFKWsu8081g6Q/AiYjoippbJpZO96p\nGh8fZ2RkBIChoSFGR0cZG6uFqCfaPF6tVqf9ednGe5FPXdH5VKvVQpefYj5+PQ/u+CC9niuVChMT\nEwCNetnOKXvokv4a+I/ACeBM4GzgAeD3gLGImJS0FNgeERdIWgNERGzMnv8osDYinp6yXPfQzUoo\npR764sVw5Eh9rGVbukktieFhOHy4yLWa3nQ99I4uLJJ0OfBfsoOid1I7KLqxzUHRS6m1Wh7HB0XN\nkpFSQZ/NuvU7n6IuLLoDuFrSHuDKbJyI2AXcD+wCHgFuyatyT91NKUpKcVLKJbU4KeVS1jiBahV6\nyqPSYlr9Eafckp+5vH9np+yhN4uIHcCObPgwcFWb+TYAG7peOzOzAolovbVdqUDWz37TczSLA4Y9\n4nu5mFlH3HJJs+ViZmYDpFQFvYw9un7HSSmX1OKklEuZ47RulVfatdAZHs4vdl976GZmKWnXOul3\nW2W23EM3s46k1ENvZ5DX2T10M7M5oFQFvaw9un7GSSmX1OKklEt6cXoRI/9cSlXQzcysPffQzawj\nc6GHfv75N/Liiw/0ezVayu1eLnlyQTcrp7lQ0BcsWMBrr73W79VoKZmDomn16NynnetxUsoltTjH\njx8vPAb4PHQzs0JImna8DB0Ft1zMrCOptlxWr17Nww8/DMD+/ftZsWIFANdddx133313P1ftJO6h\nm1luUi3ozbKi2e/VaMk99DkcJ6VcUouTUi4pxFm9ejUjIyONr3mrD69evbqQeOAeupn1We1LITqZ\n/41/B9nKlSsbxXz//v2N4ZUrV/ZvpTrklouZdcQtl/6aruXiLXQzM2rtj+YWyLp16wAYGxtjrM23\nFw0a99ATj5NSLqnFSSmXFOLcddddbNq0iU2bNgE0hu+6665C4kEfeuiSTge+BSzI5t8SEeslDQNf\nBVYA+4CPRMTR7Dm3A58ATgCfiYhtua61mVnOLr/8co4cOQLAjh07GB0dbUwvixn10CWdFRG/lHQa\n8A/Ap4H/ALwcEXdKug0Yjog1ki4E7gUuBpYDTwDnTW2Yu4duVk7uofdX1z30iPhlNnh69pwAbgDq\nH12bqd1vcg1wPXBfRJwA9knaC1wCPD3bBMzMijZneuiS5knaCRwCHo+IZ4ElETEJEBGHgHOy2ZcB\nB5qefjCb1rWy9+j6ESelXFKLk1IuKcTZsmULExMTTExMADSGt2zZUkg86NN56BHxG+B3JL0NeEDS\n+3jziaUd75+Mj483zvUcGhpidHS08UlYT7R5vFqtTvvzso33Ip+6ovOpVquFLj/FfPx6Hqzxm266\nqXGJvyQmJiYG4vVcqVQaHzL1etlOx+ehS/pvwC+BTwJjETEpaSmwPSIukLQGiIjYmM3/KLA2Ip6e\nshz30M1KKNUeeqWp5bJ+/XrWrl0LDF7LpatL/yX9lqRF2fCZwNXAbmArMJ7NdjPwUDa8FfiopAWS\nzgVWAs90lYGZWcGq1epJRb0+XN9bK4OZ9ND/NbBdUpXagc3HIuIRYCNwtaQ9wJXAHQARsQu4H9gF\nPALcktem+NTdlKKkFCelXFKLk1IuKcSpt3zrW+P14frpi0XIO5dT9tAj4gXg/S2mHwauavOcDcCG\nrtfOzMxmzPdyMbOOpNpDb7Zs2TIOHjzY79VoyfdyMbNcqYO7LQ4PF7ceRXn729/e71WYFd/LJfE4\nKeWSWpyy5hLR+gGVltMPH841fE9+bwsWLCg8BvTpPHQzs9Q1n+Hy7LPPlvJKUffQzSwXZeyVtzMy\nMsK+ffv6vRotuYduZnYKzVvo+/fvL+UWunvoicdJKZfU4qSUSxapN1F6lk/x3EM3s4F08839XoPu\nNG+Jf+ELX2hsoZeJe+hmZqRxLxcXdDOzKcp6YZF76InHSSmX1OKklEsKcSqVCuvWrWPdunX8+Mc/\nbgwXmZd76GZmBWhurXzuc59zD72jwG65mNkA2bRpEw8++CBQ+5Lo+pdDr1q1iltvvbWfq3YS99DN\nrHDr1tUeKVi4cCHHjh3r92q05B76HI6TUi6pxUkpF4D163sTpxc99FdffbWUPfRSFXQzM2vPLRcz\ny0VK93KpfznzIEqm5WJm1gtnnHFGv1dhVkpV0FPrObpPO7fjpJRLFqk3UQZ0y3k2et5Dl7Rc0jcl\nfV/SC5I+nU0flrRN0h5Jj0la1PSc2yXtlbRb0jW5rrGZDaSy38ul2dKlS/u9CrNyyh66pKXA0oio\nSloIfAe4Afg48HJE3CnpNmA4ItZIuhC4F7gYWA48AZw3tWHuHrqZDZIU7uVyyitFI+IQcCgbPiZp\nN7VCfQNweTbbZmr7W2uA64H7IuIEsE/SXuAS4Oku8zAzK8zUwl3GK0U76qFLGgFGgaeAJRExCY2i\nf0422zLgQNPTDmbTupZaz9F92rkdJ6VcUovTq28r6tu9XLJ2yxbgM9mW+tR+Scf9k/HxcUZGRgAY\nGhpidHS08QlZT7R5vFqtTvvzso33Ip+6ovOpVquFLj/FfPx6HtzxhQsXUqlUBuL1XKlUmJiYAGjU\ny3ZmdB66pPnAw8A3IuKubNpuYCwiJrM++/aIuEDSGiAiYmM236PA2oh4esoy3UM3M+tQHueh/y2w\nq17MM1uB8Wz4ZuChpukflbRA0rnASuCZjtfazEqlhC3n5MzktMUPAn8K/DtJOyU9J+laYCNwtaQ9\nwJXAHQARsQu4H9gFPALcktem+NTdlKKkFCelXFKLk1IuUP57uTTbtGlT4TGgDz30iPgH4LQ2P76q\nzXM2ABu6WC8zKwFJU8bfGC5zS7V+DKVsfC8XM7MpxsfHGwciB01X56Gbmc0FlaYLizZv3tw4o2Rs\nwC4smlZE9OVRC92Z7du3d/yc2UgpTkq5pBYnpVxSi7NkyZLCY0TMLpesdrasq95CNzPj5C30ycnJ\nxpWiZdpCdw/dzIw07uXigm5mNkX9Cs1BlMwXXKR23q7PdZ7bcVLKJbU4vfqCi7xzKVVBNzPrhWuv\nvbbfqzArbrmYmZVIMi0XMzNrr1QFPaUeXa/ipJRLanFSyiW1OGXNpVQF3cysF3wvl04Du4duZgOq\nrPdy8Ra6mdkUvfoKuryVqqCXta/Vzzgp5ZJanJRySSFOpVJh3bp1rFu3jh07djSGi8zLPXQzM2vJ\nPXQzsyl86b+ZWSJ6del/3mbynaJfljQp6fmmacOStknaI+kxSYuafna7pL2Sdku6Js+VLXuPrh9x\nUsoltTgp5ZJinF7oRw/9HuAPpkxbAzwREe8FvgncDiDpQuAjwAXAh4G/0dQvHTQzG3BLly7t9yrM\nyox66JJWAH8fEf82G38RuDwiJiUtBSoRcb6kNdS+TWNjNt83gHUR8XSLZQ5sD71SqQzU/Y/NrHhz\n5n7oLQr64YhY3PTzwxGxWNJ/B56MiK9k078EPBIRX2+xzIEt6Oeffz4vvvhiv1fDzPpk4cKFHDt2\nrN+r0VIvDor2pDL3qnf20ksv9SSO+7RzO05KuaQW57XXXis8BuSfy2y/U3RS0pKmlstPs+kHgXc2\nzbc8m9bS+Ph445u1h4aGGB0dbeza1BNtHt+yZcu0P+9mfNOmTVSrVUZGRjh+/Djj4+ONdWw+hSnP\n+NVqtbB8pr5Qilp+fbx+74sy53PFFVfQzvbt23OP14u/fy/Hy57PXXfdxc6dOwE4fvw4S5cu5Ywz\nzuC6667jpptuKiR+3XTzVyqVxm0I6vWynZm2XEaotVwuysY3AocjYqOk24DhiFiTHRS9F7gUWAY8\nDpzXqrcym5ZL/cqtItx4442NN+3Ro0dZtKh24s4VV1zBAw88UEhMG1wSDGhH0ApSmQs9dElfAcaA\nfwVMAmuBB4GvUdsa3w98JCJeyea/HfhPwHHgMxGxrc1yB6qgN8t+YYXHsf5avBiOHOnsOcPDcPhw\nMetjg2OQa0BXPfSI+JOIeEdEnB4R74qIeyLiSERcFRHvjYhr6sU8m39DRKyMiAvaFfNOVJrur7B+\n/frC7q9w2WWXccYZZzQuKKgPX3bZZbnGaZZ3Dv2KUdY4R47UtsJbPbZvr7Sc3ukHwHTK+DtLOc7q\n1asZGRlptDXqw6tXry4kHgxOD71nmnd3nnrqqcK20G+66Sbmz6/9Onbs2MEHPvABAFatWlVIPDMb\nLHfffTd33303APPnzy/lHRdLdS+X+gGCgtan7c8GddfLujObPrl76+natGkTDz74IFDbqLv88suB\n2kbdrbfe2s9VO0nX56EXYTYF/dprr+XRRx8taI3eMMj9M8vRbC9i9msjeWeeeSa/+tWv+r0aLZX6\n5lzNPfTHHnussB56Cv2zfsUoaxzRpoEeQWX79pbTleMlF2X8nc2VOKeddlrhMWCO99AffPDBnpzl\nYmZzT/Npi6+++mqj1gzaaYvTGfiWSz/ODXXLZW5wD92azYnz0Isymx56r7641QV9bnBBt3ZGRkYG\n9iyXUvfQmx06dKiwZd94440MDQ0xNDQE0Bi+8cYbC4vpHvrcjpNSLinEaT5et3///lJ+p+jA99Cb\nHS7wEr1ly5Y1ivnRo0cbw8uWLSssppkNjubWyhe+8IVSHq8rVctldHS0cROovK1evZqHH34YgP37\n97NixQoArrvuusbFBpYWt1ysnaVLlxbaEehGqXvoPihqRXFBt2b9uLBo06ZNHS87mR56kS666CLm\nz5/fuPy/PnzRRRcVFtN92v7Hkdo9Ki2nDw/nF7usv7NU49x6662NDcjh4eHGcJFXidY3UPNSqh56\nkV544YXGsCROnDjRx7WxXphuS9tb4nNPczfgyJEjPTkP/Re/+EWuyxv4lkuvdoPOPfdc9u/fD9Tu\n3VK/t8uKFSv4wQ9+kFscKwcX9Llt0aJFHD16tJBld1vTpmu5DPwW+q233tpIUlJhu1sLFy5k3rxa\nB+r1119vDC9cuLCQeGY2WJq30H/+858XtoW+Y8eOk07uqA8PDw93v5EaEX151EJ3ZjbP6WTZ7R5F\n2b59e2HL7mWMFONA8XFS+52lFCfrIBSi21qTzdeyrg78FnrzpyZQ2KdmNO1fF3WWy3S36J26DmbW\nW82nLkdE40Z9eZ+6fHKtOY2I13Nb9sD30C+66CJ2794N1Foh9bugXXDBBScdyMx33eYR8ZtCln1y\nHPdpB9W6dbVHkSqVSq4bJSd/pd50Gw9vvOjK+JV68+bN4ze/yf/92Z9TpM8n4sUOn1PiHvrKlSs5\ncOAAULuCs97TXrlyZYFRbyhw2daNs88+O/czA1rpxUWCn/rUp3jxxc7ezNOpf6Vezcy2FGZ7S/jC\nTfeFM9P9vIstpGq1elI3oD48NDRU4M25/meuSyvsPHRJ10p6UdI/Sbpttst58sknOXr0aOOIc334\nySefzG1d3+wzuS1p8eL25zpD63OdFy/OLXzpzw2e6tixYz2J04t8XnrppcJjQDlfAyLaPtr9fPHw\n4O7utqsD0L4+zKYOFFLQJc0D7gb+AHgf8DFJ589mWZOTkx1N70T7X3I1t1/wdF9E/PnPVwv/IuKi\nbpXQrzi9UlQ+zTeAOn78eE9uAFXG18DU90SthVR/nDxen6fb1lHzhUXwRgsmj9Oj29WBdjVgtnWg\nqJbLJcDeiNgPIOk+an2M/PYvc3DyLuob1q17peUu92x2TwO1bWe+AvDZz7Z4zhv/duuVV17JZTn9\njHP22WeftGVeP7i8cOHCwtovReVzxRVXnDS+fv36k/4v4phWCq+BXpy00Hx+ONBos+RxzUu7OtCu\nBtSe88a/M1VUy2UZcKBp/EfZtI41n5LTanzQTbfruJ61pdt17JmmXaNft2mz/PrYsTfvvw6g5j3B\nk89SO23KeHS1N1grGi0e69e33a+PaQ+eWl46rQGzrQMDeS+XXvWb2snzxvbtdqdqn0f7Wk7P86yD\nXt2kP/c4Tb+QxUuWtJxl8ZIlU3+hXZHUeKxfv/6k8W4cPtL6LXsar7f9uD98pPOY7YvGzbkWjXYG\n9QshZqp+wU+9dVQf3rFjR9fLbt8+Wn/SeLd1oJDTFiV9AFgXEddm42uonQy/sWkeb4aamc1Cu9MW\niyropwF7gCuBnwDPAB+LiN25BzMzM6Cgg6IR8bqk1cA2am2dL7uYm5kVq29XipqZWb4G8qBoK3ld\nqHSKGF+WNCnp+SKWn8VYLumbkr4v6QVJny4ozumSnpa0M4uT7530T441T9JzkrYWFSOLs0/Sd7Oc\nnikoxiJJX5O0O/sbXVpAjPdkOTyX/X+0wNfBZyV9T9Lzku6VtKCAGJ/JXmO5vp5bvR8lDUvaJmmP\npMckLSoozk3Z7+11Se/vNsY0ce7MXmtVSf9X0tu6CtLurl2D9KD2wfP/gBXAW4AqcH4BcS4DRoHn\nC8xlKTCaDS+kdqwh91yy5Z+V/X8a8BRwSUFxPgv8H2Brwa+Dl4DhgmNMAB/PhucDbys43jzgx8A7\nC1j2O7Lf2YJs/KvAn+Uc433A88Dp2etsG/DunJb9pvcjsBH4r9nwbcAdBcV5L3Ae8E3g/QXmcxUw\nLxu+A9jQTYyybKE3LlSKiONA/UKlXEXEt4Ecr9NsGeNQRFSz4WPAbmZ5jv4MYv0yGzydWnHKvb8m\naTnwh8CX8l52q3AUe7uKtwEfioh7ACLiRET8vKh4mauAf46IA6ecc3ZOA94qaT5wFrUPjzxdADwd\nEb+O2m0DvwX8+zwW3Ob9eAOwORveDKwqIk5E7ImIvUx/l7M84jwRb9wJ8ClgeTcxylLQc7tQaZBI\nGqH2if10QcufJ2kncAh4PCKeLSDM54G/oIAPixYCeFzSs5L+cwHLPxf4maR7snbIFyWdWUCcZn8M\n/F0RC46IHwOfA34IHAReiYgncg7zPeBDWSvkLGof7u/MOUazcyJiEmobR8A5BcbqtU8A3+hmAWUp\n6MmRtBDYAnwm21LPXUT8JiJ+h9qn/qWSLsxz+ZL+CJjM9jiab7RRlA9GxPupFY0/l3RZzsufD7wf\n+B9ZnF/8jSLWAAACNElEQVQCa3KO0SDpLcD1wNcKWv4QtS3aFdTaLwsl/UmeMaJ279eNwOPAI8BO\nIL8bfM9gFXoYqzCS/go4HhFf6WY5ZSnoB4F3NY0vz6aVUrb7uwX43xHxUNHxsrbBduDanBf9QeB6\nSS9R28q8QtL/yjlGQ0T8JPv/X4AHqLXi8vQj4EBE/GM2voVagS/Kh4HvZPkU4SrgpYg4nLVDvg78\nft5BIuKeiPi9iBijdnuSf8o7RpNJSUsAJC0FflpgrJ6QNE5tI6XrD9uyFPRngZWSVmRH6T8KFHVG\nRS+2NP8W2BURdxUVQNJv1c8AyNoGV5PzzdEi4i8j4l0R8W5qf5NvRsSf5RmjTtJZ2V4Nkt4KXENt\ndz832a78AUnvySZdCezKM8YUH6Ogdkvmh8AHJJ2h2v0LrqR2zCZXkt6e/f8u4Eagq63MqYvn5Pfj\nVmA8G74ZyGuDaLr3fZ714KQ4kq6l1rK8PiJ+3fXS8zh624sHta3LPcBeYE1BMb5C7aDRr6m9GT5e\nQIwPUtslrVLbPX0OuLaAOBdly65SOwvhrwr++1xOgWe5UOtv139nLxT4GvhtahsQVWpbtIsKinMW\n8C/A2QX/XdZSK+LPUzuI+JYCYnyL2ofrTmAsx+W+6f0IDANPZLVgGzBUUJxV1I7b/Yra1e7fKCjO\nXmB/9l59DvibbmL4wiIzs0SUpeViZman4IJuZpYIF3Qzs0S4oJuZJcIF3cwsES7oZmaJcEE3M0uE\nC7qZWSL+P8+ee0+M589tAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10953f250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Part 1a) Explore the dataset\n",
    "# Put it into pandas DataFrames\n",
    "boston_data_df = pd.DataFrame(boston.data);\n",
    "boston_target_df = pd.DataFrame(boston.target)\n",
    "\n",
    "# How many attributes and records are there?\n",
    "print boston_data_df.shape\n",
    "\n",
    "# What are the descriptive statistics?\n",
    "print boston_data_df.describe()\n",
    "\n",
    "# How are the labels distributed?\n",
    "boston_target_df.hist()\n",
    "\n",
    "# How are the attributes distributed?\n",
    "plt.figure()\n",
    "axes = boston_data_df.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         R^2        MSE\n",
      "1   0.717454  23.926098\n",
      "2   0.620171  34.779133\n",
      "3   0.783767  18.841212\n",
      "4   0.556936  30.379589\n",
      "5   0.769709  16.603228\n",
      "6   0.693492  22.287915\n",
      "7   0.828865  19.256283\n",
      "8   0.631266  33.237697\n",
      "9   0.796774  16.961117\n",
      "10  0.737993  20.302751\n",
      "R^2     0.713643\n",
      "MSE    23.657502\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Part 1b) Cross Validation \n",
    "foldnum = 0\n",
    "fold_results = pd.DataFrame()\n",
    "for train, test in cross_validation.KFold(len(boston.data), n_folds=10, shuffle=True, random_state=20160202):\n",
    "    foldnum+=1\n",
    "    [boston_tr_data, boston_te_data,\n",
    "     boston_tr_target, boston_te_target] = folds_to_split(boston.data,boston.target,train,test)\n",
    "\n",
    "    lr = linear_model.LinearRegression(normalize=True)\n",
    "    lr.fit(boston_tr_data, boston_tr_target)\n",
    "                                                                 \n",
    "    # But a nicer way to store them is in a DataFrame\n",
    "    fold_results.loc[foldnum, 'R^2'] = lr.score(boston_te_data, boston_te_target)\n",
    "    fold_results.loc[foldnum, 'MSE'] = metrics.mean_squared_error(boston_te_target, lr.predict(boston_te_data))\n",
    "\n",
    "#Now let's look at the results:\n",
    "print fold_results\n",
    "#And compute the mean error across folds:\n",
    "print fold_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTest for LinearRegression vs RidgeRegression\n",
      "Ttest_relResult(statistic=1.2154248843325628, pvalue=0.25512413165702003)\n",
      "\n",
      "\n",
      "TTest for Lasso vs RidgeRegression\n",
      "Ttest_relResult(statistic=-9.4005571317290268, pvalue=5.971187346761393e-06)\n",
      "\n",
      "\n",
      "TTest for LinearRegression vs Lasso\n",
      "Ttest_relResult(statistic=8.7799598190605046, pvalue=1.0449626130453218e-05)\n",
      "\n",
      "\n",
      "Linear Regression:\n",
      "R^2     0.713643\n",
      "MSE    23.657502\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Lasso Regularization:\n",
      "R^2     0.580869\n",
      "MSE    35.198977\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Ridge Regression: \n",
      "R^2     0.708486\n",
      "MSE    24.133678\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Part 2 Using Lasso and Ridge Regression\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "foldnum = 0\n",
    "lr_fold_results = pd.DataFrame()\n",
    "lasso_fold_results = pd.DataFrame()\n",
    "ridge_fold_results = pd.DataFrame()\n",
    "\n",
    "for train, test in cross_validation.KFold(len(boston.data), n_folds=10, shuffle=True, random_state=20160202):\n",
    "    foldnum+=1\n",
    "    [boston_tr_data, boston_te_data,\n",
    "     boston_tr_target, boston_te_target] = folds_to_split(boston.data,boston.target,train,test)\n",
    "\n",
    "    lr = linear_model.LinearRegression(normalize=True)\n",
    "    lr.fit(boston_tr_data, boston_tr_target)\n",
    "    \n",
    "    lasso = linear_model.Lasso(alpha=0.1, normalize=True, random_state=20160202)\n",
    "    lasso.fit(boston_tr_data, boston_tr_target)\n",
    "\n",
    "    ridge = linear_model.Ridge(alpha=0.1, normalize=True, random_state=20160202)\n",
    "    ridge.fit(boston_tr_data, boston_tr_target)\n",
    "                                                                 \n",
    "    # But a nicer way to store them is in a DataFrame\n",
    "    lr_fold_results.loc[foldnum, 'R^2'] = lr.score(boston_te_data, boston_te_target)\n",
    "    lr_fold_results.loc[foldnum, 'MSE'] = metrics.mean_squared_error(boston_te_target, lr.predict(boston_te_data))\n",
    "    \n",
    "    lasso_fold_results.loc[foldnum, 'R^2'] = lasso.score(boston_te_data, boston_te_target)\n",
    "    lasso_fold_results.loc[foldnum, 'MSE'] = metrics.mean_squared_error(boston_te_target, lasso.predict(boston_te_data))\n",
    "    \n",
    "    ridge_fold_results.loc[foldnum, 'R^2'] = ridge.score(boston_te_data, boston_te_target)\n",
    "    ridge_fold_results.loc[foldnum, 'MSE'] = metrics.mean_squared_error(boston_te_target, ridge.predict(boston_te_data))\n",
    "    \n",
    "#Now let's look at the results:\n",
    "print \"TTest for LinearRegression vs RidgeRegression\"\n",
    "print stats.ttest_rel(lr_fold_results['R^2'].values, ridge_fold_results['R^2'].values)\n",
    "print \"\\n\"\n",
    "\n",
    "print \"TTest for Lasso vs RidgeRegression\"\n",
    "print stats.ttest_rel(lasso_fold_results['R^2'].values, ridge_fold_results['R^2'].values)\n",
    "print \"\\n\"\n",
    "\n",
    "print \"TTest for LinearRegression vs Lasso\"\n",
    "print stats.ttest_rel(lr_fold_results['R^2'].values, lasso_fold_results['R^2'].values)\n",
    "print \"\\n\"\n",
    "\n",
    "\n",
    "#And compute the mean error across folds:\n",
    "print \"Linear Regression:\"\n",
    "print lr_fold_results.mean()\n",
    "print \"\\n\"\n",
    "\n",
    "print \"Lasso Regularization:\"\n",
    "print lasso_fold_results.mean()\n",
    "print \"\\n\"\n",
    "\n",
    "print \"Ridge Regression: \"\n",
    "print ridge_fold_results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "Now let's look at a different application for regression algorithms: classification. As we learned in class, regression algorithm can be adapted to a binary classification fairly simply. Instead of predicting some continuous value, we predict the class. So, for example, instead of predicting the diabetes condition of a patient we would predict whether or not a patient has diabetes by having the label be 1 when the patient has diabetes and 0 when the patient does not have diabetes. \n",
    "\n",
    "In this setting the regression algorithm tries to learn some combination of features to get 0 for the negative instance and 1 for the positive instances. Of course, linear regression algorithms produce continuous values, not just 1s and 0s, so we have to convert the continuous values into 1s and 0s. Usually this is done by rounding values above 0.5 to 1 and the remaining values to 0 (using, for example, the numpy [round](http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.round_.html) function). \n",
    "\n",
    "However, there's still something messy about this setting. Linear regression wants to predict continuous values and we're conscripting it to produce 1s and 0s. What if we had a regression algorithm that, by design, predicted 1s and 0s? This is exactly what logistic regression does. Let's look at an example of the difference, taken from the [scikit-learn documentation](http://scikit-learn.org/stable/auto_examples/linear_model/plot_logistic.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWwAAAELCAYAAAD9brxbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x103f89590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code source: Gael Varoquaux\n",
    "# License: BSD 3 clause\n",
    "\n",
    "# this is our test set, it's just a straight line with some\n",
    "# Gaussian noise\n",
    "xmin, xmax = -5, 5\n",
    "n_samples = 100\n",
    "np.random.seed(0)\n",
    "X = np.random.normal(size=n_samples)\n",
    "y = (X > 0).astype(np.float)\n",
    "X[X > 0] *= 4\n",
    "X += .3 * np.random.normal(size=n_samples)\n",
    "\n",
    "X = X[:, np.newaxis]\n",
    "\n",
    "#Learn a Linear Regression model\n",
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(X, y)\n",
    "\n",
    "# Learn a Logistic Regression model\n",
    "lgr = linear_model.LogisticRegression(C=1e5)\n",
    "lgr.fit(X, y)\n",
    "\n",
    "# Plot the training data (as black dots)\n",
    "plt.scatter(X.ravel(), y, color='black', zorder=20)\n",
    "\n",
    "#Create some test data\n",
    "X_test = np.linspace(-5, 10, 300).reshape(300,1)\n",
    "\n",
    "# Plot the predictions of the logistic regression model (blue line)\n",
    "plt.plot(X_test, lgr.predict(X_test), color='blue', linewidth=2)\n",
    "\n",
    "# Plot the prediction of the linear regresion model (red line)\n",
    "plt.plot(X_test, lr.predict(X_test), color='red', linewidth=2)\n",
    "\n",
    "# Make the plot prettier\n",
    "plt.axhline(.5, color='.5')\n",
    "plt.ylabel('y')\n",
    "plt.xlabel('X')\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.ylim(-.25, 1.25)\n",
    "plt.xlim(-4, 10)\n",
    "plt.title('Comparing Linear and Logisitic Regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The black dots in the plot above are the training data. The linear regression model fits that training data with the line shown in red. The logistic regression model fits the same training data with the line shown in blue. As you can see, the logistic regression model is a much closer fit to the binary training data than the linear regression model.\n",
    "\n",
    "Now let's explore logistic regression with a different data set. The [Adult dataset](http://archive.ics.uci.edu/ml/datasets/Adult) consists of 14 attributes from census data and tries to predict whether an individual has an income exceeding $50K. I've covered some of the basic steps to get the data loaded, but you can explore the original data `census_orig` (which has readable, nominal attributes) and the transformed data `census_data` and `census_labels` to get a better understanding of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data = urllib2.urlopen(\"http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\")\n",
    "census_orig = pd.read_csv(census_data, quotechar='\"', skipinitialspace=True, \n",
    "                               names=['Age','WorkClass', 'FnlWgt', 'Education', 'EducationYears', 'MaritalStatus', \n",
    "                                      'Occupation', 'Relationship', 'Race', 'Sex', \n",
    "                                      'CapitalGain', 'CapitalLoss', 'HoursPerWeek', \n",
    "                                      'NativeCountry', 'Label'],\n",
    "                               na_values=\"?\", index_col=False)\n",
    "\n",
    "census_orig = census_orig.dropna()\n",
    "\n",
    "# Convert labels from strings to boolean\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "census_labels = pd.DataFrame(label_encoder.fit_transform(census_orig.iloc[:,-1]))\n",
    "\n",
    "# Convert nominal attributes to encoded versions\n",
    "attr_encoder = feature_extraction.DictVectorizer(sparse=False)\n",
    "census_data = pd.DataFrame(attr_encoder.fit_transform(census_orig.iloc[:,:-1].T.to_dict().values()))\n",
    "census_data.columns = attr_encoder.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Logistic Regression (20 points)\n",
    "1. Learn linear and logistic regression classifiers for the census data. Perform 10-fold cross-validation (with `shuffle=True` and `random_state=20160202`) and report the mean accuracy of each classifier. Remember, you have to transform the linear regression result to get a classification.\n",
    "2. One of the important aspects data mining is data normalization. Use the `StandardScaler` to normalize your data. Now re-run the same 10-fold experiment for both classifiers. What changed? \n",
    "3. The Lasso and Ridge methods above are also part of logistic regression, although you must specify them slightly differently. You can specify the parameter `penalty='l1'` or `penalty='l2'` to specify Lasso or Ridge, respectively. The importance of regularization can be specified using the parameter C. Perform 10-fold CV with the L1 and L2 penalties and C=[0.1, 10]. Report the results of each combination (for a total of 4) averaged across folds.\n",
    "\n",
    "Note: if this were a real experiment, you would want to do your parameter search with a validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Answers 2: </h1>\n",
    "<h3>1.</h3>\n",
    "<p>\n",
    "Linear Regression Mean Accuracy    0.833996 <br>\n",
    "Logistic Regression Accuracy       0.790465 <br>\n",
    "</p>\n",
    "<h3>2.</h3>\n",
    "<p> The accuracies changed between the two models. Now with the data normalized, the Logistic Regression performs better than the Linear Regression, whereas in the original, non-standardized data, the reverse was true. It's worthy to note that the accuracy of the Logistic Regression improved significanlty ~5% <br>\n",
    "<br>\n",
    "Linear Regression Mean Accuracy    0.833864 <br>\n",
    "Logistic Regression Accuracy       0.848551 <br>\n",
    "</p>\n",
    "<h3>3. </h3>\n",
    "Lasso Log Regression <br>\n",
    "L1 0.1:     0.848087 <br>\n",
    "L1 10:     0.848551 <br> <br>\n",
    "Ridge Log Regression: <br>\n",
    "L2 0.1:     0.848485 <br>\n",
    "L2 10:     0.848551 <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    LinearReg Mean Accuracy\n",
      "1                  0.840570\n",
      "2                  0.833941\n",
      "3                  0.834881\n",
      "4                  0.839523\n",
      "5                  0.830902\n",
      "6                  0.831565\n",
      "7                  0.834218\n",
      "8                  0.827586\n",
      "9                  0.832560\n",
      "10                 0.834218\n",
      "LinearReg Mean Accuracy    0.833996\n",
      "dtype: float64\n",
      "    LogRegr Accuracy\n",
      "1           0.783560\n",
      "2           0.790520\n",
      "3           0.797082\n",
      "4           0.802056\n",
      "5           0.781167\n",
      "6           0.790119\n",
      "7           0.793103\n",
      "8           0.783820\n",
      "9           0.784483\n",
      "10          0.798740\n",
      "LogRegr Accuracy    0.790465\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Part 1 no normalization\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#maybe do your EDA here?\n",
    "foldnum = 0\n",
    "lr_fold_results = pd.DataFrame()\n",
    "lgr_fold_results = pd.DataFrame()\n",
    "\n",
    "for train, test in cross_validation.KFold(len(census_data), n_folds=10, shuffle=True, random_state=20160202):\n",
    "    foldnum+=1\n",
    "\n",
    "    [adult_tr_data, adult_te_data,\n",
    "     adult_tr_target, adult_te_target] = folds_to_split(census_data,census_labels,train,test)\n",
    "\n",
    "    lr = linear_model.LinearRegression()\n",
    "    lr.fit(adult_tr_data, adult_tr_target)\n",
    "    \n",
    "    prediction = lr.predict(adult_te_data)\n",
    "    classified_prediction = []\n",
    "    for value in range(len(prediction)):\n",
    "        classified_prediction.append(round(prediction[value]))\n",
    "    adult_te_classified_data = pd.DataFrame(classified_prediction)\n",
    "\n",
    "    lgr = linear_model.LogisticRegression(C=1e5)\n",
    "    lgr.fit(adult_tr_data, np.reshape(adult_tr_target.values,[len(adult_tr_target),]))\n",
    "\n",
    "    # But a nicer way to store them is in a DataFrame\n",
    "    lr_fold_results.loc[foldnum, 'LinearReg Mean Accuracy'] = accuracy_score(adult_te_target, adult_te_classified_data) \n",
    "    lgr_fold_results.loc[foldnum, 'LogRegr Accuracy'] = lgr.score(adult_te_data, adult_te_target)\n",
    "    \n",
    "#Now let's look at the results:\n",
    "print lr_fold_results\n",
    "#And compute the mean error across folds:\n",
    "print lr_fold_results.mean()\n",
    "\n",
    "print lgr_fold_results\n",
    "print lgr_fold_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    LinearReg Mean Accuracy\n",
      "1                  0.842559\n",
      "2                  0.832615\n",
      "3                  0.835212\n",
      "4                  0.839191\n",
      "5                  0.830570\n",
      "6                  0.831233\n",
      "7                  0.832560\n",
      "8                  0.826260\n",
      "9                  0.832891\n",
      "10                 0.835544\n",
      "LinearReg Mean Accuracy    0.833864\n",
      "dtype: float64\n",
      "    LogRegr Accuracy\n",
      "1           0.857474\n",
      "2           0.846536\n",
      "3           0.855106\n",
      "4           0.852122\n",
      "5           0.842838\n",
      "6           0.845159\n",
      "7           0.852122\n",
      "8           0.838196\n",
      "9           0.848806\n",
      "10          0.847149\n",
      "LogRegr Accuracy    0.848551\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Part 2 normalizing the data\n",
    "from sklearn import preprocessing\n",
    "\n",
    "sscaler = preprocessing.StandardScaler()\n",
    "census_data_norm = pd.DataFrame(sscaler.fit_transform(census_data.values))\n",
    "\n",
    "#maybe do your EDA here?\n",
    "foldnum = 0\n",
    "lr_fold_results = pd.DataFrame()\n",
    "lgr_fold_results = pd.DataFrame()\n",
    "\n",
    "for train, test in cross_validation.KFold(len(census_data_norm), n_folds=10, shuffle=True, random_state=20160202):\n",
    "    foldnum+=1\n",
    "\n",
    "    [adult_tr_data, adult_te_data,\n",
    "     adult_tr_target, adult_te_target] = folds_to_split(census_data_norm,census_labels,train,test)\n",
    "\n",
    "    lr = linear_model.LinearRegression()\n",
    "    lr.fit(adult_tr_data, adult_tr_target)\n",
    "    \n",
    "    prediction = lr.predict(adult_te_data)\n",
    "    classified_prediction = []\n",
    "    for value in range(len(prediction)):\n",
    "        classified_prediction.append(round(prediction[value]))\n",
    "    adult_te_classified_data = pd.DataFrame(classified_prediction)\n",
    "\n",
    "    lgr = linear_model.LogisticRegression(C=1e5)\n",
    "    lgr.fit(adult_tr_data, np.reshape(adult_tr_target.values,[len(adult_tr_target),]))\n",
    "\n",
    "    # But a nicer way to store them is in a DataFrame\n",
    "    lr_fold_results.loc[foldnum, 'LinearReg Mean Accuracy'] = accuracy_score(adult_te_target, adult_te_classified_data) \n",
    "    lgr_fold_results.loc[foldnum, 'LogRegr Accuracy'] = lgr.score(adult_te_data, adult_te_target)\n",
    "    \n",
    "#Now let's look at the results:\n",
    "print lr_fold_results\n",
    "#And compute the mean error across folds:\n",
    "print lr_fold_results.mean()\n",
    "\n",
    "print lgr_fold_results\n",
    "print lgr_fold_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 0.1:     0.848087\n",
      "dtype: float64\n",
      "L1 10:     0.848551\n",
      "dtype: float64\n",
      "L2 0.1:     0.848485\n",
      "dtype: float64\n",
      "L2 10:     0.848551\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Part 3 Lasso and Ridge using Logistic Regression\n",
    "foldnum = 0\n",
    "fold_l1_01_results = pd.DataFrame()\n",
    "fold_l1_10_results = pd.DataFrame()\n",
    "\n",
    "fold_l2_01_results = pd.DataFrame()\n",
    "fold_l2_10_results = pd.DataFrame()\n",
    "\n",
    "\n",
    "for train, test in cross_validation.KFold(len(census_data_norm), n_folds=10, shuffle=True, random_state=20160202):\n",
    "    foldnum+=1\n",
    "\n",
    "    [adult_tr_data, adult_te_data,\n",
    "     adult_tr_target, adult_te_target] = folds_to_split(census_data_norm,census_labels,train,test)\n",
    "\n",
    "    lgr_l1_01 = linear_model.LogisticRegression(penalty = 'l1', C=0.1)\n",
    "    lgr_l1_10 = linear_model.LogisticRegression(penalty = 'l1', C=10)\n",
    "    lgr_l2_01 = linear_model.LogisticRegression(penalty = 'l2', C=0.1)\n",
    "    lgr_l2_10 = linear_model.LogisticRegression(penalty = 'l2', C=10)\n",
    "    \n",
    "    lgr_l1_01.fit(adult_tr_data, np.reshape(adult_tr_target.values,[len(adult_tr_target),]))\n",
    "    lgr_l1_10.fit(adult_tr_data, np.reshape(adult_tr_target.values,[len(adult_tr_target),]))\n",
    "    \n",
    "    lgr_l2_01.fit(adult_tr_data, np.reshape(adult_tr_target.values,[len(adult_tr_target),]))\n",
    "    lgr_l2_10.fit(adult_tr_data, np.reshape(adult_tr_target.values,[len(adult_tr_target),]))\n",
    "\n",
    "    # But a nicer way to store them is in a DataFrame\n",
    "    fold_l1_01_results.loc[foldnum, 'L1 0.1: '] = lgr_l1_01.score(adult_te_data, adult_te_target)\n",
    "    fold_l1_10_results.loc[foldnum, 'L1 10: '] = lgr_l1_10.score(adult_te_data, adult_te_target)\n",
    "    \n",
    "    fold_l2_01_results.loc[foldnum, 'L2 0.1: '] = lgr_l2_01.score(adult_te_data, adult_te_target)\n",
    "    fold_l2_10_results.loc[foldnum, 'L2 10: '] = lgr_l2_10.score(adult_te_data, adult_te_target)\n",
    "\n",
    "\n",
    "#And compute the mean error across folds:\n",
    "print fold_l1_01_results.mean()\n",
    "print fold_l1_10_results.mean()\n",
    "print fold_l2_01_results.mean()\n",
    "print fold_l2_10_results.mean()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
