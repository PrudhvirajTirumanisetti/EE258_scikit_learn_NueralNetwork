{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prudhviraj Tirumanisetti\n",
    "EE 258\n",
    "ID:011489881"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: Datasets, Exploratory Data Analysis and Data Preprocessing\n",
    "\n",
    "In this assignment, you'll examine datasets, perform statistical analysis and generate visualizations to understand the data better, and perform pre-processing steps to prepare the data for analysis.\n",
    "\n",
    "In order to complete this assignment, you will need Jupyter (formerly iPython) - an interactive python environment that runs in your web browser. There are many ways to install Jupyter, but the easiest way is probably to download [Anaconda](https://www.continuum.io/downloads), which includes Python, Jupyter, and the most important data analysis tools in one installer.\n",
    "\n",
    "Once you finish the installation process, you can run the command `jupyter notebook` at the command prompt (Windows) or in a terminal (Mac OS X, Linux) to start the notebook environment. You can then open the notebooks you've downloaded from eCommons in iPython and complete the assignment.\n",
    "\n",
    "When you complete each question, I expect you to show your work as well as answer the question. If the question asks for statistics, include a cell containing the code you used to compute the statistics and anoter cell in [Markdown](https://daringfireball.net/projects/markdown/basics) format with your answer.\n",
    "\n",
    "Once you've completed the assignment, you'll need to turn in:\n",
    "*   Three Jupyter notebooks (ipynb format) corresponding to your solutions for each part. Include these in case there's an issue with your solution and we want to assign partial credit.\n",
    "\n",
    "Submit these Three files in SJSU Canvas by the deadline, 9/18/17, at 11:59pm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Instance, Attributes and Attribute Value Types (20 points)\n",
    "For this part of the assignment, we'll explore how to load data - first using built-in datasets from the scikit-learn package, and then from a simple CSV flatfile. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Preliminaries\n",
    "\n",
    "#Show plots in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# To start we import some prerequisites\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.1  0.2]\n",
      " [ 4.9  0.2]\n",
      " [ 4.7  0.2]\n",
      " [ 4.6  0.2]\n",
      " [ 5.   0.2]\n",
      " [ 5.4  0.4]\n",
      " [ 4.6  0.3]\n",
      " [ 5.   0.2]\n",
      " [ 4.4  0.2]\n",
      " [ 4.9  0.1]\n",
      " [ 5.4  0.2]\n",
      " [ 4.8  0.2]\n",
      " [ 4.8  0.1]\n",
      " [ 4.3  0.1]\n",
      " [ 5.8  0.2]\n",
      " [ 5.7  0.4]\n",
      " [ 5.4  0.4]\n",
      " [ 5.1  0.3]\n",
      " [ 5.7  0.3]\n",
      " [ 5.1  0.3]\n",
      " [ 5.4  0.2]\n",
      " [ 5.1  0.4]\n",
      " [ 4.6  0.2]\n",
      " [ 5.1  0.5]\n",
      " [ 4.8  0.2]\n",
      " [ 5.   0.2]\n",
      " [ 5.   0.4]\n",
      " [ 5.2  0.2]\n",
      " [ 5.2  0.2]\n",
      " [ 4.7  0.2]\n",
      " [ 4.8  0.2]\n",
      " [ 5.4  0.4]\n",
      " [ 5.2  0.1]\n",
      " [ 5.5  0.2]\n",
      " [ 4.9  0.1]\n",
      " [ 5.   0.2]\n",
      " [ 5.5  0.2]\n",
      " [ 4.9  0.1]\n",
      " [ 4.4  0.2]\n",
      " [ 5.1  0.2]\n",
      " [ 5.   0.3]\n",
      " [ 4.5  0.3]\n",
      " [ 4.4  0.2]\n",
      " [ 5.   0.6]\n",
      " [ 5.1  0.4]\n",
      " [ 4.8  0.3]\n",
      " [ 5.1  0.2]\n",
      " [ 4.6  0.2]\n",
      " [ 5.3  0.2]\n",
      " [ 5.   0.2]\n",
      " [ 7.   1.4]\n",
      " [ 6.4  1.5]\n",
      " [ 6.9  1.5]\n",
      " [ 5.5  1.3]\n",
      " [ 6.5  1.5]\n",
      " [ 5.7  1.3]\n",
      " [ 6.3  1.6]\n",
      " [ 4.9  1. ]\n",
      " [ 6.6  1.3]\n",
      " [ 5.2  1.4]\n",
      " [ 5.   1. ]\n",
      " [ 5.9  1.5]\n",
      " [ 6.   1. ]\n",
      " [ 6.1  1.4]\n",
      " [ 5.6  1.3]\n",
      " [ 6.7  1.4]\n",
      " [ 5.6  1.5]\n",
      " [ 5.8  1. ]\n",
      " [ 6.2  1.5]\n",
      " [ 5.6  1.1]\n",
      " [ 5.9  1.8]\n",
      " [ 6.1  1.3]\n",
      " [ 6.3  1.5]\n",
      " [ 6.1  1.2]\n",
      " [ 6.4  1.3]\n",
      " [ 6.6  1.4]\n",
      " [ 6.8  1.4]\n",
      " [ 6.7  1.7]\n",
      " [ 6.   1.5]\n",
      " [ 5.7  1. ]\n",
      " [ 5.5  1.1]\n",
      " [ 5.5  1. ]\n",
      " [ 5.8  1.2]\n",
      " [ 6.   1.6]\n",
      " [ 5.4  1.5]\n",
      " [ 6.   1.6]\n",
      " [ 6.7  1.5]\n",
      " [ 6.3  1.3]\n",
      " [ 5.6  1.3]\n",
      " [ 5.5  1.3]\n",
      " [ 5.5  1.2]\n",
      " [ 6.1  1.4]\n",
      " [ 5.8  1.2]\n",
      " [ 5.   1. ]\n",
      " [ 5.6  1.3]\n",
      " [ 5.7  1.2]\n",
      " [ 5.7  1.3]\n",
      " [ 6.2  1.3]\n",
      " [ 5.1  1.1]\n",
      " [ 5.7  1.3]\n",
      " [ 6.3  2.5]\n",
      " [ 5.8  1.9]\n",
      " [ 7.1  2.1]\n",
      " [ 6.3  1.8]\n",
      " [ 6.5  2.2]\n",
      " [ 7.6  2.1]\n",
      " [ 4.9  1.7]\n",
      " [ 7.3  1.8]\n",
      " [ 6.7  1.8]\n",
      " [ 7.2  2.5]\n",
      " [ 6.5  2. ]\n",
      " [ 6.4  1.9]\n",
      " [ 6.8  2.1]\n",
      " [ 5.7  2. ]\n",
      " [ 5.8  2.4]\n",
      " [ 6.4  2.3]\n",
      " [ 6.5  1.8]\n",
      " [ 7.7  2.2]\n",
      " [ 7.7  2.3]\n",
      " [ 6.   1.5]\n",
      " [ 6.9  2.3]\n",
      " [ 5.6  2. ]\n",
      " [ 7.7  2. ]\n",
      " [ 6.3  1.8]\n",
      " [ 6.7  2.1]\n",
      " [ 7.2  1.8]\n",
      " [ 6.2  1.8]\n",
      " [ 6.1  1.8]\n",
      " [ 6.4  2.1]\n",
      " [ 7.2  1.6]\n",
      " [ 7.4  1.9]\n",
      " [ 7.9  2. ]\n",
      " [ 6.4  2.2]\n",
      " [ 6.3  1.5]\n",
      " [ 6.1  1.4]\n",
      " [ 7.7  2.3]\n",
      " [ 6.3  2.4]\n",
      " [ 6.4  1.8]\n",
      " [ 6.   1.8]\n",
      " [ 6.9  2.1]\n",
      " [ 6.7  2.4]\n",
      " [ 6.9  2.3]\n",
      " [ 5.8  1.9]\n",
      " [ 6.8  2.3]\n",
      " [ 6.7  2.5]\n",
      " [ 6.7  2.3]\n",
      " [ 6.3  1.9]\n",
      " [ 6.5  2. ]\n",
      " [ 6.2  2.3]\n",
      " [ 5.9  1.8]]\n",
      "{'target_names': array(['setosa', 'versicolor', 'virginica'], \n",
      "      dtype='|S10'), 'data': array([[ 5.1,  3.5,  1.4,  0.2],\n",
      "       [ 4.9,  3. ,  1.4,  0.2],\n",
      "       [ 4.7,  3.2,  1.3,  0.2],\n",
      "       [ 4.6,  3.1,  1.5,  0.2],\n",
      "       [ 5. ,  3.6,  1.4,  0.2],\n",
      "       [ 5.4,  3.9,  1.7,  0.4],\n",
      "       [ 4.6,  3.4,  1.4,  0.3],\n",
      "       [ 5. ,  3.4,  1.5,  0.2],\n",
      "       [ 4.4,  2.9,  1.4,  0.2],\n",
      "       [ 4.9,  3.1,  1.5,  0.1],\n",
      "       [ 5.4,  3.7,  1.5,  0.2],\n",
      "       [ 4.8,  3.4,  1.6,  0.2],\n",
      "       [ 4.8,  3. ,  1.4,  0.1],\n",
      "       [ 4.3,  3. ,  1.1,  0.1],\n",
      "       [ 5.8,  4. ,  1.2,  0.2],\n",
      "       [ 5.7,  4.4,  1.5,  0.4],\n",
      "       [ 5.4,  3.9,  1.3,  0.4],\n",
      "       [ 5.1,  3.5,  1.4,  0.3],\n",
      "       [ 5.7,  3.8,  1.7,  0.3],\n",
      "       [ 5.1,  3.8,  1.5,  0.3],\n",
      "       [ 5.4,  3.4,  1.7,  0.2],\n",
      "       [ 5.1,  3.7,  1.5,  0.4],\n",
      "       [ 4.6,  3.6,  1. ,  0.2],\n",
      "       [ 5.1,  3.3,  1.7,  0.5],\n",
      "       [ 4.8,  3.4,  1.9,  0.2],\n",
      "       [ 5. ,  3. ,  1.6,  0.2],\n",
      "       [ 5. ,  3.4,  1.6,  0.4],\n",
      "       [ 5.2,  3.5,  1.5,  0.2],\n",
      "       [ 5.2,  3.4,  1.4,  0.2],\n",
      "       [ 4.7,  3.2,  1.6,  0.2],\n",
      "       [ 4.8,  3.1,  1.6,  0.2],\n",
      "       [ 5.4,  3.4,  1.5,  0.4],\n",
      "       [ 5.2,  4.1,  1.5,  0.1],\n",
      "       [ 5.5,  4.2,  1.4,  0.2],\n",
      "       [ 4.9,  3.1,  1.5,  0.1],\n",
      "       [ 5. ,  3.2,  1.2,  0.2],\n",
      "       [ 5.5,  3.5,  1.3,  0.2],\n",
      "       [ 4.9,  3.1,  1.5,  0.1],\n",
      "       [ 4.4,  3. ,  1.3,  0.2],\n",
      "       [ 5.1,  3.4,  1.5,  0.2],\n",
      "       [ 5. ,  3.5,  1.3,  0.3],\n",
      "       [ 4.5,  2.3,  1.3,  0.3],\n",
      "       [ 4.4,  3.2,  1.3,  0.2],\n",
      "       [ 5. ,  3.5,  1.6,  0.6],\n",
      "       [ 5.1,  3.8,  1.9,  0.4],\n",
      "       [ 4.8,  3. ,  1.4,  0.3],\n",
      "       [ 5.1,  3.8,  1.6,  0.2],\n",
      "       [ 4.6,  3.2,  1.4,  0.2],\n",
      "       [ 5.3,  3.7,  1.5,  0.2],\n",
      "       [ 5. ,  3.3,  1.4,  0.2],\n",
      "       [ 7. ,  3.2,  4.7,  1.4],\n",
      "       [ 6.4,  3.2,  4.5,  1.5],\n",
      "       [ 6.9,  3.1,  4.9,  1.5],\n",
      "       [ 5.5,  2.3,  4. ,  1.3],\n",
      "       [ 6.5,  2.8,  4.6,  1.5],\n",
      "       [ 5.7,  2.8,  4.5,  1.3],\n",
      "       [ 6.3,  3.3,  4.7,  1.6],\n",
      "       [ 4.9,  2.4,  3.3,  1. ],\n",
      "       [ 6.6,  2.9,  4.6,  1.3],\n",
      "       [ 5.2,  2.7,  3.9,  1.4],\n",
      "       [ 5. ,  2. ,  3.5,  1. ],\n",
      "       [ 5.9,  3. ,  4.2,  1.5],\n",
      "       [ 6. ,  2.2,  4. ,  1. ],\n",
      "       [ 6.1,  2.9,  4.7,  1.4],\n",
      "       [ 5.6,  2.9,  3.6,  1.3],\n",
      "       [ 6.7,  3.1,  4.4,  1.4],\n",
      "       [ 5.6,  3. ,  4.5,  1.5],\n",
      "       [ 5.8,  2.7,  4.1,  1. ],\n",
      "       [ 6.2,  2.2,  4.5,  1.5],\n",
      "       [ 5.6,  2.5,  3.9,  1.1],\n",
      "       [ 5.9,  3.2,  4.8,  1.8],\n",
      "       [ 6.1,  2.8,  4. ,  1.3],\n",
      "       [ 6.3,  2.5,  4.9,  1.5],\n",
      "       [ 6.1,  2.8,  4.7,  1.2],\n",
      "       [ 6.4,  2.9,  4.3,  1.3],\n",
      "       [ 6.6,  3. ,  4.4,  1.4],\n",
      "       [ 6.8,  2.8,  4.8,  1.4],\n",
      "       [ 6.7,  3. ,  5. ,  1.7],\n",
      "       [ 6. ,  2.9,  4.5,  1.5],\n",
      "       [ 5.7,  2.6,  3.5,  1. ],\n",
      "       [ 5.5,  2.4,  3.8,  1.1],\n",
      "       [ 5.5,  2.4,  3.7,  1. ],\n",
      "       [ 5.8,  2.7,  3.9,  1.2],\n",
      "       [ 6. ,  2.7,  5.1,  1.6],\n",
      "       [ 5.4,  3. ,  4.5,  1.5],\n",
      "       [ 6. ,  3.4,  4.5,  1.6],\n",
      "       [ 6.7,  3.1,  4.7,  1.5],\n",
      "       [ 6.3,  2.3,  4.4,  1.3],\n",
      "       [ 5.6,  3. ,  4.1,  1.3],\n",
      "       [ 5.5,  2.5,  4. ,  1.3],\n",
      "       [ 5.5,  2.6,  4.4,  1.2],\n",
      "       [ 6.1,  3. ,  4.6,  1.4],\n",
      "       [ 5.8,  2.6,  4. ,  1.2],\n",
      "       [ 5. ,  2.3,  3.3,  1. ],\n",
      "       [ 5.6,  2.7,  4.2,  1.3],\n",
      "       [ 5.7,  3. ,  4.2,  1.2],\n",
      "       [ 5.7,  2.9,  4.2,  1.3],\n",
      "       [ 6.2,  2.9,  4.3,  1.3],\n",
      "       [ 5.1,  2.5,  3. ,  1.1],\n",
      "       [ 5.7,  2.8,  4.1,  1.3],\n",
      "       [ 6.3,  3.3,  6. ,  2.5],\n",
      "       [ 5.8,  2.7,  5.1,  1.9],\n",
      "       [ 7.1,  3. ,  5.9,  2.1],\n",
      "       [ 6.3,  2.9,  5.6,  1.8],\n",
      "       [ 6.5,  3. ,  5.8,  2.2],\n",
      "       [ 7.6,  3. ,  6.6,  2.1],\n",
      "       [ 4.9,  2.5,  4.5,  1.7],\n",
      "       [ 7.3,  2.9,  6.3,  1.8],\n",
      "       [ 6.7,  2.5,  5.8,  1.8],\n",
      "       [ 7.2,  3.6,  6.1,  2.5],\n",
      "       [ 6.5,  3.2,  5.1,  2. ],\n",
      "       [ 6.4,  2.7,  5.3,  1.9],\n",
      "       [ 6.8,  3. ,  5.5,  2.1],\n",
      "       [ 5.7,  2.5,  5. ,  2. ],\n",
      "       [ 5.8,  2.8,  5.1,  2.4],\n",
      "       [ 6.4,  3.2,  5.3,  2.3],\n",
      "       [ 6.5,  3. ,  5.5,  1.8],\n",
      "       [ 7.7,  3.8,  6.7,  2.2],\n",
      "       [ 7.7,  2.6,  6.9,  2.3],\n",
      "       [ 6. ,  2.2,  5. ,  1.5],\n",
      "       [ 6.9,  3.2,  5.7,  2.3],\n",
      "       [ 5.6,  2.8,  4.9,  2. ],\n",
      "       [ 7.7,  2.8,  6.7,  2. ],\n",
      "       [ 6.3,  2.7,  4.9,  1.8],\n",
      "       [ 6.7,  3.3,  5.7,  2.1],\n",
      "       [ 7.2,  3.2,  6. ,  1.8],\n",
      "       [ 6.2,  2.8,  4.8,  1.8],\n",
      "       [ 6.1,  3. ,  4.9,  1.8],\n",
      "       [ 6.4,  2.8,  5.6,  2.1],\n",
      "       [ 7.2,  3. ,  5.8,  1.6],\n",
      "       [ 7.4,  2.8,  6.1,  1.9],\n",
      "       [ 7.9,  3.8,  6.4,  2. ],\n",
      "       [ 6.4,  2.8,  5.6,  2.2],\n",
      "       [ 6.3,  2.8,  5.1,  1.5],\n",
      "       [ 6.1,  2.6,  5.6,  1.4],\n",
      "       [ 7.7,  3. ,  6.1,  2.3],\n",
      "       [ 6.3,  3.4,  5.6,  2.4],\n",
      "       [ 6.4,  3.1,  5.5,  1.8],\n",
      "       [ 6. ,  3. ,  4.8,  1.8],\n",
      "       [ 6.9,  3.1,  5.4,  2.1],\n",
      "       [ 6.7,  3.1,  5.6,  2.4],\n",
      "       [ 6.9,  3.1,  5.1,  2.3],\n",
      "       [ 5.8,  2.7,  5.1,  1.9],\n",
      "       [ 6.8,  3.2,  5.9,  2.3],\n",
      "       [ 6.7,  3.3,  5.7,  2.5],\n",
      "       [ 6.7,  3. ,  5.2,  2.3],\n",
      "       [ 6.3,  2.5,  5. ,  1.9],\n",
      "       [ 6.5,  3. ,  5.2,  2. ],\n",
      "       [ 6.2,  3.4,  5.4,  2.3],\n",
      "       [ 5.9,  3. ,  5.1,  1.8]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), 'DESCR': 'Iris Plants Database\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML iris datasets.\\nhttp://archive.ics.uci.edu/ml/datasets/Iris\\n\\nThe famous Iris database, first used by Sir R.A Fisher\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\nReferences\\n----------\\n   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...\\n', 'feature_names': ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']}\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "iris_trimmed = iris.data[:,[0,3]]\n",
    "print iris_trimmed\n",
    "print iris\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Plants Database\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML iris datasets.\n",
      "http://archive.ics.uci.edu/ml/datasets/Iris\n",
      "\n",
      "The famous Iris database, first used by Sir R.A Fisher\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      "References\n",
      "----------\n",
      "   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's load the famous Iris dataset in scikit-learn!\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# The datasets in scikit-learn come with lots of metadata documenting the data. \n",
    "#Let's look at a full description of this dataset\n",
    "\n",
    "# Sepal Length\n",
    "# Petal Width\n",
    "print iris.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "# Now let's see what attributes are available\n",
    "\n",
    "print iris.feature_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n"
     ]
    }
   ],
   "source": [
    "# We can look at the raw data too. First let's get the dimensions of the data\n",
    "\n",
    "print iris.data.shape\n",
    "\n",
    "#This tells us there are 150 rows, each of which contains 4 feature values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.1  3.5  1.4  0.2]\n",
      " [ 4.9  3.   1.4  0.2]\n",
      " [ 4.7  3.2  1.3  0.2]\n",
      " [ 4.6  3.1  1.5  0.2]\n",
      " [ 5.   3.6  1.4  0.2]\n",
      " [ 5.4  3.9  1.7  0.4]\n",
      " [ 4.6  3.4  1.4  0.3]\n",
      " [ 5.   3.4  1.5  0.2]\n",
      " [ 4.4  2.9  1.4  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 5.4  3.7  1.5  0.2]\n",
      " [ 4.8  3.4  1.6  0.2]\n",
      " [ 4.8  3.   1.4  0.1]\n",
      " [ 4.3  3.   1.1  0.1]\n",
      " [ 5.8  4.   1.2  0.2]\n",
      " [ 5.7  4.4  1.5  0.4]\n",
      " [ 5.4  3.9  1.3  0.4]\n",
      " [ 5.1  3.5  1.4  0.3]\n",
      " [ 5.7  3.8  1.7  0.3]\n",
      " [ 5.1  3.8  1.5  0.3]\n",
      " [ 5.4  3.4  1.7  0.2]\n",
      " [ 5.1  3.7  1.5  0.4]\n",
      " [ 4.6  3.6  1.   0.2]\n",
      " [ 5.1  3.3  1.7  0.5]\n",
      " [ 4.8  3.4  1.9  0.2]\n",
      " [ 5.   3.   1.6  0.2]\n",
      " [ 5.   3.4  1.6  0.4]\n",
      " [ 5.2  3.5  1.5  0.2]\n",
      " [ 5.2  3.4  1.4  0.2]\n",
      " [ 4.7  3.2  1.6  0.2]\n",
      " [ 4.8  3.1  1.6  0.2]\n",
      " [ 5.4  3.4  1.5  0.4]\n",
      " [ 5.2  4.1  1.5  0.1]\n",
      " [ 5.5  4.2  1.4  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 5.   3.2  1.2  0.2]\n",
      " [ 5.5  3.5  1.3  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 4.4  3.   1.3  0.2]\n",
      " [ 5.1  3.4  1.5  0.2]\n",
      " [ 5.   3.5  1.3  0.3]\n",
      " [ 4.5  2.3  1.3  0.3]\n",
      " [ 4.4  3.2  1.3  0.2]\n",
      " [ 5.   3.5  1.6  0.6]\n",
      " [ 5.1  3.8  1.9  0.4]\n",
      " [ 4.8  3.   1.4  0.3]\n",
      " [ 5.1  3.8  1.6  0.2]\n",
      " [ 4.6  3.2  1.4  0.2]\n",
      " [ 5.3  3.7  1.5  0.2]\n",
      " [ 5.   3.3  1.4  0.2]\n",
      " [ 7.   3.2  4.7  1.4]\n",
      " [ 6.4  3.2  4.5  1.5]\n",
      " [ 6.9  3.1  4.9  1.5]\n",
      " [ 5.5  2.3  4.   1.3]\n",
      " [ 6.5  2.8  4.6  1.5]\n",
      " [ 5.7  2.8  4.5  1.3]\n",
      " [ 6.3  3.3  4.7  1.6]\n",
      " [ 4.9  2.4  3.3  1. ]\n",
      " [ 6.6  2.9  4.6  1.3]\n",
      " [ 5.2  2.7  3.9  1.4]\n",
      " [ 5.   2.   3.5  1. ]\n",
      " [ 5.9  3.   4.2  1.5]\n",
      " [ 6.   2.2  4.   1. ]\n",
      " [ 6.1  2.9  4.7  1.4]\n",
      " [ 5.6  2.9  3.6  1.3]\n",
      " [ 6.7  3.1  4.4  1.4]\n",
      " [ 5.6  3.   4.5  1.5]\n",
      " [ 5.8  2.7  4.1  1. ]\n",
      " [ 6.2  2.2  4.5  1.5]\n",
      " [ 5.6  2.5  3.9  1.1]\n",
      " [ 5.9  3.2  4.8  1.8]\n",
      " [ 6.1  2.8  4.   1.3]\n",
      " [ 6.3  2.5  4.9  1.5]\n",
      " [ 6.1  2.8  4.7  1.2]\n",
      " [ 6.4  2.9  4.3  1.3]\n",
      " [ 6.6  3.   4.4  1.4]\n",
      " [ 6.8  2.8  4.8  1.4]\n",
      " [ 6.7  3.   5.   1.7]\n",
      " [ 6.   2.9  4.5  1.5]\n",
      " [ 5.7  2.6  3.5  1. ]\n",
      " [ 5.5  2.4  3.8  1.1]\n",
      " [ 5.5  2.4  3.7  1. ]\n",
      " [ 5.8  2.7  3.9  1.2]\n",
      " [ 6.   2.7  5.1  1.6]\n",
      " [ 5.4  3.   4.5  1.5]\n",
      " [ 6.   3.4  4.5  1.6]\n",
      " [ 6.7  3.1  4.7  1.5]\n",
      " [ 6.3  2.3  4.4  1.3]\n",
      " [ 5.6  3.   4.1  1.3]\n",
      " [ 5.5  2.5  4.   1.3]\n",
      " [ 5.5  2.6  4.4  1.2]\n",
      " [ 6.1  3.   4.6  1.4]\n",
      " [ 5.8  2.6  4.   1.2]\n",
      " [ 5.   2.3  3.3  1. ]\n",
      " [ 5.6  2.7  4.2  1.3]\n",
      " [ 5.7  3.   4.2  1.2]\n",
      " [ 5.7  2.9  4.2  1.3]\n",
      " [ 6.2  2.9  4.3  1.3]\n",
      " [ 5.1  2.5  3.   1.1]\n",
      " [ 5.7  2.8  4.1  1.3]\n",
      " [ 6.3  3.3  6.   2.5]\n",
      " [ 5.8  2.7  5.1  1.9]\n",
      " [ 7.1  3.   5.9  2.1]\n",
      " [ 6.3  2.9  5.6  1.8]\n",
      " [ 6.5  3.   5.8  2.2]\n",
      " [ 7.6  3.   6.6  2.1]\n",
      " [ 4.9  2.5  4.5  1.7]\n",
      " [ 7.3  2.9  6.3  1.8]\n",
      " [ 6.7  2.5  5.8  1.8]\n",
      " [ 7.2  3.6  6.1  2.5]\n",
      " [ 6.5  3.2  5.1  2. ]\n",
      " [ 6.4  2.7  5.3  1.9]\n",
      " [ 6.8  3.   5.5  2.1]\n",
      " [ 5.7  2.5  5.   2. ]\n",
      " [ 5.8  2.8  5.1  2.4]\n",
      " [ 6.4  3.2  5.3  2.3]\n",
      " [ 6.5  3.   5.5  1.8]\n",
      " [ 7.7  3.8  6.7  2.2]\n",
      " [ 7.7  2.6  6.9  2.3]\n",
      " [ 6.   2.2  5.   1.5]\n",
      " [ 6.9  3.2  5.7  2.3]\n",
      " [ 5.6  2.8  4.9  2. ]\n",
      " [ 7.7  2.8  6.7  2. ]\n",
      " [ 6.3  2.7  4.9  1.8]\n",
      " [ 6.7  3.3  5.7  2.1]\n",
      " [ 7.2  3.2  6.   1.8]\n",
      " [ 6.2  2.8  4.8  1.8]\n",
      " [ 6.1  3.   4.9  1.8]\n",
      " [ 6.4  2.8  5.6  2.1]\n",
      " [ 7.2  3.   5.8  1.6]\n",
      " [ 7.4  2.8  6.1  1.9]\n",
      " [ 7.9  3.8  6.4  2. ]\n",
      " [ 6.4  2.8  5.6  2.2]\n",
      " [ 6.3  2.8  5.1  1.5]\n",
      " [ 6.1  2.6  5.6  1.4]\n",
      " [ 7.7  3.   6.1  2.3]\n",
      " [ 6.3  3.4  5.6  2.4]\n",
      " [ 6.4  3.1  5.5  1.8]\n",
      " [ 6.   3.   4.8  1.8]\n",
      " [ 6.9  3.1  5.4  2.1]\n",
      " [ 6.7  3.1  5.6  2.4]\n",
      " [ 6.9  3.1  5.1  2.3]\n",
      " [ 5.8  2.7  5.1  1.9]\n",
      " [ 6.8  3.2  5.9  2.3]\n",
      " [ 6.7  3.3  5.7  2.5]\n",
      " [ 6.7  3.   5.2  2.3]\n",
      " [ 6.3  2.5  5.   1.9]\n",
      " [ 6.5  3.   5.2  2. ]\n",
      " [ 6.2  3.4  5.4  2.3]\n",
      " [ 5.9  3.   5.1  1.8]]\n"
     ]
    }
   ],
   "source": [
    "# Now let's see the rows and columns\n",
    "\n",
    "print iris.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n",
      "(150,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "# That's just the data, but since this is a dataset where the goal is to predict particular\n",
    "# labels, we can look at those labels. First we'll look at the shape, then the raw values\n",
    "\n",
    "print iris.target_names\n",
    "\n",
    "print iris.target.shape\n",
    "\n",
    "print iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (10 points)\n",
    "Okay, now that we've looked at the data, time for some questions:\n",
    "1. How many objects or instances are in the dataset?\n",
    "2. How many attributes are in the dataset?\n",
    "3. What type is each attribute (nominal, ordinal, interval or ratio?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "1. How many objects or instances are in the dataset?<br> 150 objects <br><br>\n",
    "2. How many attributes are in the dataset?<br> 4 attributes/features <br><br>\n",
    "3. What type is each attribute (nominal, ordinal, interval or ratio?)<br> They are all ratio attributes\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Loading a different dataset\n",
    "Now let's try something a bit more difficult - loading a dataset from the web (which won't have all the pretty metadata that scikit gives us). We'll look at a dataset from the Data.gov website. This dataset contains preliminary accident and incident data from the Federal Aviation Administration, and can be downloaded from [the Data.gov webpage](http://catalog.data.gov/dataset/preliminary-accidentincident-data-daily-data-file), but we'll download it using Python as part of this notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  UPDATED ENTRY_DATE EVENT_LCL_DATE EVENT_LCL_TIME     LOC_CITY_NAME  \\\n",
      "0      No  19-JAN-16      18-JAN-16      22:41:00Z  COLORADO SPRINGS   \n",
      "1      No  19-JAN-16      18-JAN-16      21:45:00Z            VENICE   \n",
      "2      No  19-JAN-16      18-JAN-16      21:02:00Z        SCOTTSDALE   \n",
      "3      No  19-JAN-16      18-JAN-16      19:13:00Z         PENSACOLA   \n",
      "4      No  19-JAN-16      18-JAN-16      16:45:00Z            DUBLIN   \n",
      "5      No  19-JAN-16      16-JAN-16      18:05:00Z       BROOKSVILLE   \n",
      "6      No  19-JAN-16      16-JAN-16      01:00:00Z            AUBURN   \n",
      "7      No  19-JAN-16      12-JAN-16      22:30:00Z          BAUDETTE   \n",
      "8      No  19-JAN-16      15-JAN-16      21:07:00Z           SEATTLE   \n",
      "9      No  19-JAN-16      18-JAN-16      00:45:00Z           MADISON   \n",
      "\n",
      "  LOC_STATE_NAME LOC_CNTRY_NAME  \\\n",
      "0       Colorado            NaN   \n",
      "1        Florida            NaN   \n",
      "2        Arizona            NaN   \n",
      "3        Florida            NaN   \n",
      "4        Georgia            NaN   \n",
      "5        Florida            NaN   \n",
      "6     California            NaN   \n",
      "7      Minnesota            NaN   \n",
      "8     Washington            NaN   \n",
      "9        Georgia            NaN   \n",
      "\n",
      "                                            RMK_TEXT EVENT_TYPE_DESC  \\\n",
      "0  AIRCRAFT FORCE LANDED IN A FIELD, NEAR COLORAD...        Incident   \n",
      "1     AIRCRAFT ON LANDING GEAR COLLAPSED, VENICE, FL        Incident   \n",
      "2  AIRCRAFT ON LANDING, RIGHT MAIN GEAR COLLAPSED...        Incident   \n",
      "3  AIRCRAFT ON LANDING, STRUCK THE PROPELLER, PEN...        Incident   \n",
      "4    AIRCRAFT ON TAKEOFF, GEAR COLLAPSED, DUBLIN, GA        Incident   \n",
      "5           AIRCRAFT LANDED GEAR UP, BROOKSVILLE, FL        Incident   \n",
      "6                AIRCRAFT LANDED GEAR UP, AUBURN, CA        Incident   \n",
      "7  N355HL AEROSPATIALE AS355 ROTORCRAFT FORCE LAN...        Incident   \n",
      "8  AIRCRAFT ON STARTUP, ENGINE CAUGHT FIRE, ARFF ...        Incident   \n",
      "9  AIRCRAFT STRUCK A TELEPHONE POLE AND CRASHED O...        Accident   \n",
      "\n",
      "                 FSDO_DESC REGIST_NBR FLT_NBR ACFT_OPRTR ACFT_MAKE_NAME  \\\n",
      "0       FAA Denver FSDO-03     N7909N     NaN        NaN         CESSNA   \n",
      "1        FAA Miami FSDO-19     N761EP     NaN        NaN         CESSNA   \n",
      "2   FAA Scottsdale FSDO-07     N706SB     NaN        NaN       DASSAULT   \n",
      "3   FAA Birmingham FSDO-09     N7048G     NaN        NaN         CESSNA   \n",
      "4      FAA Atlanta FSDO-11       N68X     NaN        NaN          PIPER   \n",
      "5        FAA Miami FSDO-19     N55134     NaN        NaN          PIPER   \n",
      "6   FAA Sacramento FSDO-25     N5214B     NaN        NaN         MOONEY   \n",
      "7  FAA Minneapolis FSDO-15     N355HL     NaN        NaN            NaN   \n",
      "8      FAA Seattle FSDO-01     N2587C     NaN        NaN          PIPER   \n",
      "9      FAA Atlanta FSDO-11     N6135M     NaN        NaN         CESSNA   \n",
      "\n",
      "    ACFT_MODEL_NAME  ACFT_MISSING_FLAG ACFT_DMG_DESC FLT_ACTIVITY  \\\n",
      "0               172                NaN          None  Instruction   \n",
      "1               210                NaN       Unknown          NaN   \n",
      "2  MYSTERE FALCON20                NaN         Minor          NaN   \n",
      "3               172                NaN         Minor  Instruction   \n",
      "4              PA30                NaN       Unknown          NaN   \n",
      "5              PA34                NaN       Unknown          NaN   \n",
      "6               M20                NaN         Minor          NaN   \n",
      "7               NaN                NaN         Minor        Other   \n",
      "8              PA38                NaN       Unknown          NaN   \n",
      "9               152                NaN   Substantial          NaN   \n",
      "\n",
      "        FLT_PHASE  FAR_PART MAX_INJ_LVL FATAL_FLAG  FLT_CRW_INJ_NONE  \\\n",
      "0   LANDING (LDG)       NaN        None        NaN                 2   \n",
      "1   LANDING (LDG)       NaN        None        NaN                 1   \n",
      "2   LANDING (LDG)       NaN        None        NaN                 1   \n",
      "3   LANDING (LDG)       NaN        None        NaN                 1   \n",
      "4   TAKEOFF (TOF)       NaN        None        NaN                 2   \n",
      "5   LANDING (LDG)       NaN        None        NaN                 1   \n",
      "6   LANDING (LDG)       NaN        None        NaN                 1   \n",
      "7   UNKNOWN (UNK)       NaN        None        NaN                 1   \n",
      "8  STANDING (STD)       NaN        None        NaN                 1   \n",
      "9   LANDING (LDG)       NaN     Serious        NaN               NaN   \n",
      "\n",
      "   FLT_CRW_INJ_MINOR  FLT_CRW_INJ_SERIOUS  FLT_CRW_INJ_FATAL  FLT_CRW_INJ_UNK  \\\n",
      "0                NaN                  NaN                NaN              NaN   \n",
      "1                NaN                  NaN                NaN              NaN   \n",
      "2                NaN                  NaN                NaN              NaN   \n",
      "3                NaN                  NaN                NaN              NaN   \n",
      "4                NaN                  NaN                NaN              NaN   \n",
      "5                NaN                  NaN                NaN              NaN   \n",
      "6                NaN                  NaN                NaN              NaN   \n",
      "7                NaN                  NaN                NaN              NaN   \n",
      "8                NaN                  NaN                NaN              NaN   \n",
      "9                NaN                    2                NaN              NaN   \n",
      "\n",
      "   CBN_CRW_INJ_NONE  CBN_CRW_INJ_MINOR  CBN_CRW_INJ_SERIOUS  \\\n",
      "0               NaN                NaN                  NaN   \n",
      "1               NaN                NaN                  NaN   \n",
      "2               NaN                NaN                  NaN   \n",
      "3               NaN                NaN                  NaN   \n",
      "4               NaN                NaN                  NaN   \n",
      "5               NaN                NaN                  NaN   \n",
      "6               NaN                NaN                  NaN   \n",
      "7               NaN                NaN                  NaN   \n",
      "8               NaN                NaN                  NaN   \n",
      "9               NaN                NaN                  NaN   \n",
      "\n",
      "   CBN_CRW_INJ_FATAL  CBN_CRW_INJ_UNK  PAX_INJ_NONE  PAX_INJ_MINOR  \\\n",
      "0                NaN              NaN           NaN            NaN   \n",
      "1                NaN              NaN           NaN            NaN   \n",
      "2                NaN              NaN             3            NaN   \n",
      "3                NaN              NaN           NaN            NaN   \n",
      "4                NaN              NaN           NaN            NaN   \n",
      "5                NaN              NaN             2            NaN   \n",
      "6                NaN              NaN           NaN            NaN   \n",
      "7                NaN              NaN             2            NaN   \n",
      "8                NaN              NaN           NaN            NaN   \n",
      "9                NaN              NaN           NaN            NaN   \n",
      "\n",
      "   PAX_INJ_SERIOUS  PAX_INJ_FATAL  PAX_INJ_UNK  GRND_INJ_NONE  GRND_INJ_MINOR  \\\n",
      "0              NaN            NaN          NaN            NaN             NaN   \n",
      "1              NaN            NaN          NaN            NaN             NaN   \n",
      "2              NaN            NaN          NaN            NaN             NaN   \n",
      "3              NaN            NaN          NaN            NaN             NaN   \n",
      "4              NaN            NaN          NaN            NaN             NaN   \n",
      "5              NaN            NaN          NaN            NaN             NaN   \n",
      "6              NaN            NaN          NaN            NaN             NaN   \n",
      "7              NaN            NaN          NaN            NaN             NaN   \n",
      "8              NaN            NaN          NaN            NaN             NaN   \n",
      "9              NaN            NaN          NaN            NaN             NaN   \n",
      "\n",
      "   GRND_INJ_SERIOUS  GRND_INJ_FATAL  GRND_INJ_UNK  \n",
      "0               NaN             NaN           NaN  \n",
      "1               NaN             NaN           NaN  \n",
      "2               NaN             NaN           NaN  \n",
      "3               NaN             NaN           NaN  \n",
      "4               NaN             NaN           NaN  \n",
      "5               NaN             NaN           NaN  \n",
      "6               NaN             NaN           NaN  \n",
      "7               NaN             NaN           NaN  \n",
      "8               NaN             NaN           NaN  \n",
      "9               NaN             NaN           NaN  \n"
     ]
    }
   ],
   "source": [
    "#Let's download the data using the link on the page above:\n",
    "faa_data = urllib2.urlopen(\"http://www.asias.faa.gov/pls/apex/f?p=100:93::FLOW_EXCEL_OUTPUT_R2161113456916636_en\")\n",
    "\n",
    "#We can use a module called pandas to parse and manipulate this data\n",
    "faa_dataset = pd.read_csv(faa_data, quotechar='\"', skipinitialspace=True)\n",
    "\n",
    "# By default, only a few columns are shown. Setting this option allows us to see all the columns\n",
    "pd.set_option('display.max_columns', None) \n",
    "# Let's look at the first ten rows\n",
    "print faa_dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['No' '19-JAN-16' '18-JAN-16' ..., nan nan nan]\n",
      " ['No' '19-JAN-16' '18-JAN-16' ..., nan nan nan]\n",
      " ['No' '19-JAN-16' '18-JAN-16' ..., nan nan nan]\n",
      " ..., \n",
      " ['Yes' '04-JAN-16' '02-JAN-16' ..., nan nan nan]\n",
      " ['Yes' '04-JAN-16' '02-JAN-16' ..., nan nan nan]\n",
      " ['Yes' '04-JAN-16' '02-JAN-16' ..., nan nan nan]]\n"
     ]
    }
   ],
   "source": [
    "#We can also convert this into the same sort of data matrix we used in the previously with the .values property\n",
    "print faa_dataset.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (10 points)\n",
    "Looking at the data above, answer the following questions.\n",
    "1.    How many objects or instances are in the dataset?\n",
    "2.    How many attributes are in the dataset?\n",
    "3.    Can you name a:\n",
    "       * nominal attribute\n",
    "       * ordinal attribute\n",
    "       * interval attribute\n",
    "       * ratio attribute\n",
    "\n",
    "    in the dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "1. How many objects or instances are in the dataset? <br>\n",
    "63 <br><br>\n",
    "\n",
    "2. How many attributes are in the dataset?<br>\n",
    "42 \n",
    "<br> <br>\n",
    "3. Can you name a: <br>\n",
    "nominal attribute - LOC_STATE_NAME<br>\n",
    "ordinal attribute - ACFT_DMG_DESC<br>\n",
    "interval attribute - ENTRY_DATE<br>\n",
    "ratio attribute - FLT_CRW_INJ_NONE<br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63, 42)\n"
     ]
    }
   ],
   "source": [
    "# Qustion 2 code\n",
    "# Number of objects and attributes\n",
    "print faa_dataset.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
