{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PrudhvirajTirumanisetti\n",
    "EE 258 ID:011489881"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4: Instance-Based Classification, Clustering, and Text Mining\n",
    "In this assignment, you will experiment with k-Nearest Neighbors, one of the simplest, yet most popular instance-based classification method, as well as several clustering techniques including k-Means and Gaussian Mixture Models. Finally, you will have the opportunity to test your text mining skills on a couple of real problems.\n",
    "\n",
    "Like the previous assignments, you will be expected to complete the assignment by answering the questions in Markdown cells and supporting your answer with corresponding code cells. Wherever appropriate, please use the parameter settings `random_state=20160217` and `shuffle=True` to ensure consistent results across runs. Please submit your solution as three iPython notebooks (for Part 1, Part 2, and Part 3) and three PDF files (for Part 1, Part 2, and Part 3) generated from your iPython notebook that show all code execution results. The due date for this assignment is 10/26/17 at 11:59pm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Preliminaries\n",
    "\n",
    "#Show plots in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import datasets, preprocessing, cross_validation, feature_extraction\n",
    "from sklearn import linear_model, svm, metrics, ensemble, neighbors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib2\n",
    "\n",
    "# Helper functions\n",
    "def folds_to_split(data,targets,train,test):\n",
    "    data_tr = pd.DataFrame(data).iloc[train]\n",
    "    data_te = pd.DataFrame(data).iloc[test]\n",
    "    labels_tr = pd.DataFrame(targets).iloc[train]\n",
    "    labels_te = pd.DataFrame(targets).iloc[test]\n",
    "    return [data_tr, data_te, labels_tr, labels_te]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Instance-Based Classification (25 points)\n",
    "Instance-based classification approaches forgo a learned model and instead rely on similarity measures between test instances and training instances. This approach is powerful, yet has its drawbacks. Instance-based methods can avoid particular model biases and implement more flexible decision boundaries. However, as the amount of training data goes, scalability bottlenecks can develop and making predictions using these methods can become cumbersome.\n",
    "\n",
    "The most popular and widely-used instance-based classification technique is k-nearest neighbors. This classifier classifies test instances using the *k* most similar training instances in the data, where *k* is a user-specified parameter. Scikit-learn has support for finding the [nearest neighbors](http://scikit-learn.org/stable/modules/neighbors.html) of an instance through brute-force (computing all pairwise distances) or using more query-efficient data structures such as the K-D tree or ball tree. This functionality provides the basis of the [KNeighborsClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier) which implements k-Nearest Neighbors classification with the classifier interface you've come to know and love. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors for Iris\n",
    "Let's take a look at how k-Nearest Neighbors works on our favorite dataset, Iris. Since the amount of training data can have a significant influence on the performance, we'll perform 5-fold cross-validation. We'll explore the impact of three parameters to the algorithm: k, the number of neighbors; the distance metric used to find the most similar instances; and finally whether to give each of the neighbors an equal vote or weight their vote based on their distance to the instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for different parameters of K-Nearest Neighbors\n",
      "k=1    p=1       w=uniform       0.953\n",
      "k=1    p=2       w=uniform       0.960\n",
      "k=1    p=100     w=uniform       0.973\n",
      "k=5    p=1       w=uniform       0.967\n",
      "k=5    p=2       w=uniform       0.967\n",
      "k=5    p=100     w=uniform       0.973\n",
      "k=15   p=1       w=uniform       0.967\n",
      "k=15   p=2       w=uniform       0.967\n",
      "k=15   p=100     w=uniform       0.960\n",
      "k=1    p=1       w=distance      0.953\n",
      "k=1    p=2       w=distance      0.960\n",
      "k=1    p=100     w=distance      0.973\n",
      "k=5    p=1       w=distance      0.960\n",
      "k=5    p=2       w=distance      0.960\n",
      "k=5    p=100     w=distance      0.980\n",
      "k=15   p=1       w=distance      0.967\n",
      "k=15   p=2       w=distance      0.973\n",
      "k=15   p=100     w=distance      0.980\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "iris_knn_results = pd.DataFrame()\n",
    "foldnum=0\n",
    "for train, test in cross_validation.KFold(len(iris.target), shuffle=True, n_folds=5,\n",
    "                                           random_state=20160217):\n",
    "    foldnum+=1\n",
    "    [iris_tr_data, iris_te_data, \n",
    "     iris_tr_targets, iris_te_targets] = folds_to_split(iris.data, iris.target, train, test)\n",
    "    # Give neighbors equal weight (uniform) or base weight on distance\n",
    "    for weight in ['uniform', 'distance']:\n",
    "        # Use 1, 2 or 15 neighbors to deteremine the class\n",
    "        for k in [1, 5, 15]:\n",
    "            #Use L1 (Manhattan), L2 (Euclidean), or L100 (approaching supremum distance)\n",
    "            for degree in [1, 2, 100]:\n",
    "                knn = neighbors.KNeighborsClassifier(n_neighbors=k, p=degree, weights=weight)\n",
    "                knn.fit(iris_tr_data.values, iris_tr_targets.values.ravel())\n",
    "                iris_knn_results.loc[foldnum, 'k={:<5}p={:<8}w={:<10}'.format(k, degree, weight)] = knn.score(iris_te_data.values,\n",
    "                                                                                                              iris_te_targets.values.ravel())\n",
    "print \"Results for different parameters of K-Nearest Neighbors\"\n",
    "print iris_knn_results.mean().apply(lambda x : '%0.3f' % x)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the results, we can see a few trends. First, the performance is best at k=5. This is likely because using only a single neighbor can increase the variability of the classifications, while setting k high (15) can include many extraneous training instances that belong to a different class. The poor performance of a high k-value can be mitigated somewhat by using distance-weighted instance votes. If the extraneous training instances are far from the test instance, giving these distant and irrelevant training instances a lower weight prevents them from having a disproportionate influence on the classification output. Finally, we can see that, for this dataset, higher degree distances (which emphasize the most different attribute value) tend to lead to slightly better performance overall. \n",
    "\n",
    "This is a case where kNN is fairly successful, partially because the space is low-dimensional (with only four attributes) and the instances cluster together well. What happens in higher dimensional spaces? For example, the following snippet will make a classification dataset with 250 attributes, not just 4. \n",
    "```\n",
    "[data, targets] = datasets.make_classification(n_samples=500, n_features=250,\n",
    "                                                     random_state=20160217)\n",
    "```\n",
    "Do you think k-Nearest Neighbors will perform well? We've also assumed that training data is abundant relative to the size of the test set. How does classifier performance change as the training set decreases?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Dimensionality, Training Data Coverage and kNN (16 points)\n",
    "1. Use the `make_classification` function to generate data as in the example snippet above. Vary the `n_features` parameter from 10, 25, 50, 100, 250, and 500. Perform 5-fold cross validation for each of these generated datasets, training a k-Nearest Neighbors classifier on the training data and applying it to the test data for each fold. Report the mean accuracy across folds for each generated dataset. How does kNN perform as the number of features increases?\n",
    "2. Use the `make_classification` function as above to generate data with 50 features. Perform 2, 3, 5, 10, and 20 folds. Use the **test set** as your training data and the **training set** as your test data. This means that kNN will have access to anywhere between 50% and 5% of the data as examples to use during classification. Report the mean accuracy across folds for each number of folds. How does the performance of kNN decay as the number of example instances decraeses?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Answers 1. </h1>\n",
    "<p> 1. As expected, the performance of the kNN suffers when the dimensionality increases.<br>\n",
    "The more features our dataset has, the less accurate the model because the neighboors that the kNN uses are not very close to the datapoint we are trying to compare to. Our data is more sparse, so the accuracy will be lower. <br>\n",
    "Results:<br>\n",
    "f=10      k=5    p=100     w=distance      0.810 <br>\n",
    "f=25      k=5    p=100     w=distance      0.754 <br>\n",
    "f=50      k=5    p=100     w=distance      0.712 <br>\n",
    "f=100     k=5    p=100     w=distance      0.658 <br>\n",
    "f=250     k=5    p=100     w=distance      0.584 <br>\n",
    "f=500     k=5    p=100     w=distance      0.576 <br>\n",
    "</p>\n",
    "\n",
    "<p> 2. The performance of kNN also drops when we use fewer test instances, because now we have fewer points to compare our test set to. While the accuracy drops, it did not drop by as much as I would have expected. This means that our train and test data are stratified, so it's fairly easy to predict the class. Also this leads to the conclusion that kNN might be a possible algorithm to be used if we don't have much data available. <br>\n",
    "Results:<br>\n",
    "f=2       k=5    p=100     w=distance      0.668 <br>\n",
    "f=3       k=5    p=100     w=distance      0.681 <br>\n",
    "f=5       k=5    p=100     w=distance      0.665 <br>\n",
    "f=10      k=5    p=100     w=distance      0.642 <br>\n",
    "f=20      k=5    p=100     w=distance      0.613 <br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f=10      k=5    p=100     w=distance      0.810\n",
      "f=25      k=5    p=100     w=distance      0.754\n",
      "f=50      k=5    p=100     w=distance      0.712\n",
      "f=100     k=5    p=100     w=distance      0.658\n",
      "f=250     k=5    p=100     w=distance      0.584\n",
      "f=500     k=5    p=100     w=distance      0.576\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Part 1\n",
    "gen_knn_results = pd.DataFrame()\n",
    "foldnum=0\n",
    "\n",
    "k = 5\n",
    "weight = 'distance'\n",
    "for feature in [10, 25, 50, 100, 250, 500]:\n",
    "    [data, targets] = datasets.make_classification(n_samples=500, n_features=feature,\n",
    "                                                     random_state=20160217)\n",
    "    for train, test in cross_validation.KFold(len(data), shuffle=True, n_folds=5,\n",
    "                                           random_state=20160217):\n",
    "        foldnum+=1\n",
    "        [gen_tr_data, gen_te_data, \n",
    "         gen_tr_targets, gen_te_targets] = folds_to_split(data, targets, train, test)\n",
    "        \n",
    "        knn = neighbors.KNeighborsClassifier(n_neighbors=k, p=degree, weights=weight)\n",
    "        knn.fit(gen_tr_data.values, gen_tr_targets.values.ravel())\n",
    "        gen_knn_results.loc[foldnum, 'f={:<8}k={:<5}p={:<8}w={:<10}'.format(feature, k, degree, weight)] = knn.score(gen_te_data.values,\n",
    "                                                                                                              gen_te_targets.values.ravel())\n",
    "    \n",
    "\n",
    "print gen_knn_results.mean().apply(lambda x : '%0.3f' % x)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f=2       k=5    p=100     w=distance      0.668\n",
      "f=3       k=5    p=100     w=distance      0.681\n",
      "f=5       k=5    p=100     w=distance      0.665\n",
      "f=10      k=5    p=100     w=distance      0.642\n",
      "f=20      k=5    p=100     w=distance      0.613\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Part 2\n",
    "gen_knn_results = pd.DataFrame()\n",
    "foldnum=0\n",
    "\n",
    "k = 5\n",
    "weight = 'distance'\n",
    "\n",
    "[data, targets] = datasets.make_classification(n_samples=500, n_features=50,\n",
    "                                                     random_state=20160217)\n",
    "for folds in [2, 3, 5, 10, 20]:\n",
    "    for train, test in cross_validation.KFold(len(data), shuffle=True, n_folds=folds,\n",
    "                                           random_state=20160217):\n",
    "        \n",
    "        foldnum+=1\n",
    "        [gen_tr_data, gen_te_data, \n",
    "         gen_tr_targets, gen_te_targets] = folds_to_split(data, targets, train, test)\n",
    "        \n",
    "        knn = neighbors.KNeighborsClassifier(n_neighbors=k, p=degree, weights=weight)\n",
    "        knn.fit(gen_te_data.values, gen_te_targets.values.ravel())\n",
    "        gen_knn_results.loc[foldnum, 'f={:<8}k={:<5}p={:<8}w={:<10}'.format(folds, k, degree, weight)] = knn.score(gen_tr_data.values,\n",
    "                                                                                                              gen_tr_targets.values.ravel())\n",
    "    \n",
    "\n",
    "print gen_knn_results.mean().apply(lambda x : '%0.3f' % x)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting Cancer using KNN\n",
    "Now let's use k-Nearest Neighbors for a slightly more interesting dataset. The data was collected at the University of Wisconsin, Madison to try and predict breast cancer. Each instance consists of a series of image features from cells grown from a sample of a potentially cancerous mass. You can read more about the dataset at the [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29). To get you started, I'll provide you with the data loading command, but you should be comfortable enough with the data mining pipeline to do the rest: parse the data, split out labels and attributes, perform any necessary pre-processing steps and choose an evaluation strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Real-world kNN (9 points)\n",
    "Perform k-Nearest Neighbor classification on the Breast Cancer Dataset corresponding to the URL above. Use a validation set to choose the best k for the dataset, then perform a cross-validated experiment using the chosen value of k and a "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Answers 2 </h1>\n",
    "<p> When changing a bunch of parameters and using the validation set, i got the best performing attributes to be <br>\n",
    "Folds=2   k=8    p=1       w=distance       0.98947 <br>\n",
    "\n",
    "Then when performing a cross-validatated expriment using the chosen valies above I get the following accuracy: <br>\n",
    "Folds=2   k=8    p=1       w=distance      0.95957\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_url = urllib2.urlopen(\"http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\")\n",
    "\n",
    "bc = pd.read_csv(bc_url, \n",
    "                 quotechar='\"', \n",
    "                 skipinitialspace=True, \n",
    "                 names=['ID', \n",
    "                        'Diagnosis',\n",
    "                       '3',\n",
    "                       '4',\n",
    "                       '5',\n",
    "                       '6',\n",
    "                       '7',\n",
    "                       '8',\n",
    "                       '9',\n",
    "                       '10',\n",
    "                       '11',\n",
    "                       '12',\n",
    "                       '13',\n",
    "                       '14',\n",
    "                       '15',\n",
    "                       '16',\n",
    "                       '17',\n",
    "                       '18',\n",
    "                       '19',\n",
    "                       '20',\n",
    "                       '21',\n",
    "                       '22',\n",
    "                       '23',\n",
    "                       '24',\n",
    "                       '25',\n",
    "                       '26',\n",
    "                       '27',\n",
    "                       '28',\n",
    "                       '29',\n",
    "                       '30',\n",
    "                       '31',\n",
    "                       '32'], na_values=\"?\")\n",
    "\n",
    "# Drop missing values\n",
    "bc = bc.dropna()\n",
    "\n",
    "# Extract labels and data values\n",
    "bc_targets = bc['Diagnosis']\n",
    "bc = bc.drop('Diagnosis', axis=1)\n",
    "\n",
    "# standardize the data using Standard Scaler\n",
    "std_scaler = preprocessing.StandardScaler()\n",
    "bc_data = pd.DataFrame(std_scaler.fit_transform(bc))\n",
    "bc_targets = pd.DataFrame(bc_targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height has been deprecated.\n",
      "\n",
      "569\n",
      "569\n",
      "Results for different parameters of K-Nearest Neighbors\n",
      "f=2    k=1    p=1       w=uniform       0.95817\n",
      "f=2    k=1    p=2       w=uniform       0.95811\n",
      "f=2    k=1    p=100     w=uniform       0.86913\n",
      "f=2    k=2    p=1       w=uniform       0.97906\n",
      "f=2    k=2    p=2       w=uniform       0.97906\n",
      "f=2    k=2    p=100     w=uniform       0.94254\n",
      "f=2    k=3    p=1       w=uniform       0.98427\n",
      "f=2    k=3    p=2       w=uniform       0.96332\n",
      "f=2    k=3    p=100     w=uniform       0.93196\n",
      "f=2    k=4    p=1       w=uniform       0.97385\n",
      "f=2    k=4    p=2       w=uniform       0.98427\n",
      "f=2    k=4    p=100     w=uniform       0.92675\n",
      "f=2    k=5    p=1       w=uniform       0.97895\n",
      "f=2    k=5    p=2       w=uniform       0.95274\n",
      "f=2    k=5    p=100     w=uniform       0.90570\n",
      "f=2    k=6    p=1       w=uniform       0.97374\n",
      "f=2    k=6    p=2       w=uniform       0.97374\n",
      "f=2    k=6    p=100     w=uniform       0.93723\n",
      "f=2    k=7    p=1       w=uniform       0.97895\n",
      "f=2    k=7    p=2       w=uniform       0.96853\n",
      "f=2    k=7    p=100     w=uniform       0.91623\n",
      "f=2    k=8    p=1       w=uniform       0.97900\n",
      "f=2    k=8    p=2       w=uniform       0.97379\n",
      "f=2    k=8    p=100     w=uniform       0.92670\n",
      "f=2    k=9    p=1       w=uniform       0.96853\n",
      "f=2    k=9    p=2       w=uniform       0.96848\n",
      "f=2    k=9    p=100     w=uniform       0.94232\n",
      "f=2    k=10   p=1       w=uniform       0.96332\n",
      "f=2    k=10   p=2       w=uniform       0.96848\n",
      "f=2    k=10   p=100     w=uniform       0.93191\n",
      "f=2    k=11   p=1       w=uniform       0.96332\n",
      "f=2    k=11   p=2       w=uniform       0.97374\n",
      "f=2    k=11   p=100     w=uniform       0.92659\n",
      "f=2    k=12   p=1       w=uniform       0.97379\n",
      "f=2    k=12   p=2       w=uniform       0.96327\n",
      "f=2    k=12   p=100     w=uniform       0.93191\n",
      "f=2    k=13   p=1       w=uniform       0.96859\n",
      "f=2    k=13   p=2       w=uniform       0.96327\n",
      "f=2    k=13   p=100     w=uniform       0.92133\n",
      "f=2    k=14   p=1       w=uniform       0.97379\n",
      "f=2    k=14   p=2       w=uniform       0.96853\n",
      "f=2    k=14   p=100     w=uniform       0.92664\n",
      "f=2    k=1    p=1       w=distance      0.95817\n",
      "f=2    k=1    p=2       w=distance      0.95811\n",
      "f=2    k=1    p=100     w=distance      0.86913\n",
      "f=2    k=2    p=1       w=distance      0.95817\n",
      "f=2    k=2    p=2       w=distance      0.95811\n",
      "f=2    k=2    p=100     w=distance      0.86913\n",
      "f=2    k=3    p=1       w=distance      0.98427\n",
      "f=2    k=3    p=2       w=distance      0.96332\n",
      "f=2    k=3    p=100     w=distance      0.93196\n",
      "f=2    k=4    p=1       w=distance      0.97385\n",
      "f=2    k=4    p=2       w=distance      0.97379\n",
      "f=2    k=4    p=100     w=distance      0.90581\n",
      "f=2    k=5    p=1       w=distance      0.97895\n",
      "f=2    k=5    p=2       w=distance      0.95800\n",
      "f=2    k=5    p=100     w=distance      0.90570\n",
      "f=2    k=6    p=1       w=distance      0.98421\n",
      "f=2    k=6    p=2       w=distance      0.96848\n",
      "f=2    k=6    p=100     w=distance      0.92670\n",
      "f=2    k=7    p=1       w=distance      0.97895\n",
      "f=2    k=7    p=2       w=distance      0.97379\n",
      "f=2    k=7    p=100     w=distance      0.91623\n",
      "f=2    k=8    p=1       w=distance      0.98947\n",
      "f=2    k=8    p=2       w=distance      0.98427\n",
      "f=2    k=8    p=100     w=distance      0.93191\n",
      "f=2    k=9    p=1       w=distance      0.97379\n",
      "f=2    k=9    p=2       w=distance      0.97374\n",
      "f=2    k=9    p=100     w=distance      0.94232\n",
      "f=2    k=10   p=1       w=distance      0.98427\n",
      "f=2    k=10   p=2       w=distance      0.97374\n",
      "f=2    k=10   p=100     w=distance      0.93706\n",
      "f=2    k=11   p=1       w=distance      0.96332\n",
      "f=2    k=11   p=2       w=distance      0.97374\n",
      "f=2    k=11   p=100     w=distance      0.93185\n",
      "f=2    k=12   p=1       w=distance      0.97900\n",
      "f=2    k=12   p=2       w=distance      0.97900\n",
      "f=2    k=12   p=100     w=distance      0.92659\n",
      "f=2    k=13   p=1       w=distance      0.96859\n",
      "f=2    k=13   p=2       w=distance      0.96327\n",
      "f=2    k=13   p=100     w=distance      0.92659\n",
      "f=2    k=14   p=1       w=distance      0.97906\n",
      "f=2    k=14   p=2       w=distance      0.96853\n",
      "f=2    k=14   p=100     w=distance      0.92659\n",
      "f=3    k=1    p=1       w=uniform       0.95552\n",
      "f=3    k=1    p=2       w=uniform       0.92936\n",
      "f=3    k=1    p=100     w=uniform       0.88747\n",
      "f=3    k=2    p=1       w=uniform       0.97381\n",
      "f=3    k=2    p=2       w=uniform       0.97119\n",
      "f=3    k=2    p=100     w=uniform       0.92665\n",
      "f=3    k=3    p=1       w=uniform       0.97377\n",
      "f=3    k=3    p=2       w=uniform       0.96075\n",
      "f=3    k=3    p=100     w=uniform       0.90842\n",
      "f=3    k=4    p=1       w=uniform       0.97904\n",
      "f=3    k=4    p=2       w=uniform       0.98165\n",
      "f=3    k=4    p=100     w=uniform       0.93453\n",
      "f=3    k=5    p=1       w=uniform       0.97121\n",
      "f=3    k=5    p=2       w=uniform       0.96861\n",
      "f=3    k=5    p=100     w=uniform       0.92411\n",
      "f=3    k=6    p=1       w=uniform       0.97646\n",
      "f=3    k=6    p=2       w=uniform       0.97388\n",
      "f=3    k=6    p=100     w=uniform       0.91884\n",
      "f=3    k=7    p=1       w=uniform       0.97386\n",
      "f=3    k=7    p=2       w=uniform       0.96865\n",
      "f=3    k=7    p=100     w=uniform       0.91103\n",
      "f=3    k=8    p=1       w=uniform       0.97646\n",
      "f=3    k=8    p=2       w=uniform       0.97386\n",
      "f=3    k=8    p=100     w=uniform       0.93711\n",
      "f=3    k=9    p=1       w=uniform       0.97646\n",
      "f=3    k=9    p=2       w=uniform       0.97121\n",
      "f=3    k=9    p=100     w=uniform       0.91624\n",
      "f=3    k=10   p=1       w=uniform       0.96863\n",
      "f=3    k=10   p=2       w=uniform       0.96598\n",
      "f=3    k=10   p=100     w=uniform       0.92928\n",
      "f=3    k=11   p=1       w=uniform       0.97123\n",
      "f=3    k=11   p=2       w=uniform       0.96073\n",
      "f=3    k=11   p=100     w=uniform       0.92151\n",
      "f=3    k=12   p=1       w=uniform       0.96861\n",
      "f=3    k=12   p=2       w=uniform       0.96598\n",
      "f=3    k=12   p=100     w=uniform       0.92409\n",
      "f=3    k=13   p=1       w=uniform       0.96596\n",
      "f=3    k=13   p=2       w=uniform       0.96859\n",
      "f=3    k=13   p=100     w=uniform       0.92407\n",
      "f=3    k=14   p=1       w=uniform       0.97123\n",
      "f=3    k=14   p=2       w=uniform       0.96600\n",
      "f=3    k=14   p=100     w=uniform       0.92932\n",
      "f=3    k=1    p=1       w=distance      0.95552\n",
      "f=3    k=1    p=2       w=distance      0.92936\n",
      "f=3    k=1    p=100     w=distance      0.88747\n",
      "f=3    k=2    p=1       w=distance      0.95552\n",
      "f=3    k=2    p=2       w=distance      0.92936\n",
      "f=3    k=2    p=100     w=distance      0.88747\n",
      "f=3    k=3    p=1       w=distance      0.97377\n",
      "f=3    k=3    p=2       w=distance      0.96075\n",
      "f=3    k=3    p=100     w=distance      0.90842\n",
      "f=3    k=4    p=1       w=distance      0.98165\n",
      "f=3    k=4    p=2       w=distance      0.95811\n",
      "f=3    k=4    p=100     w=distance      0.90319\n",
      "f=3    k=5    p=1       w=distance      0.97121\n",
      "f=3    k=5    p=2       w=distance      0.96861\n",
      "f=3    k=5    p=100     w=distance      0.92411\n",
      "f=3    k=6    p=1       w=distance      0.97384\n",
      "f=3    k=6    p=2       w=distance      0.97125\n",
      "f=3    k=6    p=100     w=distance      0.90842\n",
      "f=3    k=7    p=1       w=distance      0.97386\n",
      "f=3    k=7    p=2       w=distance      0.97125\n",
      "f=3    k=7    p=100     w=distance      0.91103\n",
      "f=3    k=8    p=1       w=distance      0.97384\n",
      "f=3    k=8    p=2       w=distance      0.96861\n",
      "f=3    k=8    p=100     w=distance      0.91626\n",
      "f=3    k=9    p=1       w=distance      0.97646\n",
      "f=3    k=9    p=2       w=distance      0.97121\n",
      "f=3    k=9    p=100     w=distance      0.91624\n",
      "f=3    k=10   p=1       w=distance      0.97908\n",
      "f=3    k=10   p=2       w=distance      0.96859\n",
      "f=3    k=10   p=100     w=distance      0.92149\n",
      "f=3    k=11   p=1       w=distance      0.97384\n",
      "f=3    k=11   p=2       w=distance      0.96073\n",
      "f=3    k=11   p=100     w=distance      0.92151\n",
      "f=3    k=12   p=1       w=distance      0.97381\n",
      "f=3    k=12   p=2       w=distance      0.96859\n",
      "f=3    k=12   p=100     w=distance      0.92151\n",
      "f=3    k=13   p=1       w=distance      0.96596\n",
      "f=3    k=13   p=2       w=distance      0.96859\n",
      "f=3    k=13   p=100     w=distance      0.92669\n",
      "f=3    k=14   p=1       w=distance      0.96861\n",
      "f=3    k=14   p=2       w=distance      0.97121\n",
      "f=3    k=14   p=100     w=distance      0.92146\n",
      "f=5    k=1    p=1       w=uniform       0.95026\n",
      "f=5    k=1    p=2       w=uniform       0.93191\n",
      "f=5    k=1    p=100     w=uniform       0.89658\n",
      "f=5    k=2    p=1       w=uniform       0.97645\n",
      "f=5    k=2    p=2       w=uniform       0.96598\n",
      "f=5    k=2    p=100     w=uniform       0.93456\n",
      "f=5    k=3    p=1       w=uniform       0.98169\n",
      "f=5    k=3    p=2       w=uniform       0.96073\n",
      "f=5    k=3    p=100     w=uniform       0.91229\n",
      "f=5    k=4    p=1       w=uniform       0.98037\n",
      "f=5    k=4    p=2       w=uniform       0.97907\n",
      "f=5    k=4    p=100     w=uniform       0.92933\n",
      "f=5    k=5    p=1       w=uniform       0.97644\n",
      "f=5    k=5    p=2       w=uniform       0.96859\n",
      "f=5    k=5    p=100     w=uniform       0.91886\n",
      "f=5    k=6    p=1       w=uniform       0.98167\n",
      "f=5    k=6    p=2       w=uniform       0.97905\n",
      "f=5    k=6    p=100     w=uniform       0.93457\n",
      "f=5    k=7    p=1       w=uniform       0.98167\n",
      "f=5    k=7    p=2       w=uniform       0.96726\n",
      "f=5    k=7    p=100     w=uniform       0.92145\n",
      "f=5    k=8    p=1       w=uniform       0.98166\n",
      "f=5    k=8    p=2       w=uniform       0.98166\n",
      "f=5    k=8    p=100     w=uniform       0.93981\n",
      "f=5    k=9    p=1       w=uniform       0.97774\n",
      "f=5    k=9    p=2       w=uniform       0.96987\n",
      "f=5    k=9    p=100     w=uniform       0.93324\n",
      "f=5    k=10   p=1       w=uniform       0.97250\n",
      "f=5    k=10   p=2       w=uniform       0.97380\n",
      "f=5    k=10   p=100     w=uniform       0.93588\n",
      "f=5    k=11   p=1       w=uniform       0.97251\n",
      "f=5    k=11   p=2       w=uniform       0.96988\n",
      "f=5    k=11   p=100     w=uniform       0.93456\n",
      "f=5    k=12   p=1       w=uniform       0.97121\n",
      "f=5    k=12   p=2       w=uniform       0.97512\n",
      "f=5    k=12   p=100     w=uniform       0.94110\n",
      "f=5    k=13   p=1       w=uniform       0.96987\n",
      "f=5    k=13   p=2       w=uniform       0.96858\n",
      "f=5    k=13   p=100     w=uniform       0.93326\n",
      "f=5    k=14   p=1       w=uniform       0.97121\n",
      "f=5    k=14   p=2       w=uniform       0.97251\n",
      "f=5    k=14   p=100     w=uniform       0.94110\n",
      "f=5    k=1    p=1       w=distance      0.95026\n",
      "f=5    k=1    p=2       w=distance      0.93191\n",
      "f=5    k=1    p=100     w=distance      0.89658\n",
      "f=5    k=2    p=1       w=distance      0.95026\n",
      "f=5    k=2    p=2       w=distance      0.93191\n",
      "f=5    k=2    p=100     w=distance      0.89658\n",
      "f=5    k=3    p=1       w=distance      0.98169\n",
      "f=5    k=3    p=2       w=distance      0.96073\n",
      "f=5    k=3    p=100     w=distance      0.91229\n",
      "f=5    k=4    p=1       w=distance      0.97776\n",
      "f=5    k=4    p=2       w=distance      0.96467\n",
      "f=5    k=4    p=100     w=distance      0.91228\n",
      "f=5    k=5    p=1       w=distance      0.97644\n",
      "f=5    k=5    p=2       w=distance      0.96859\n",
      "f=5    k=5    p=100     w=distance      0.91886\n",
      "f=5    k=6    p=1       w=distance      0.97906\n",
      "f=5    k=6    p=2       w=distance      0.97121\n",
      "f=5    k=6    p=100     w=distance      0.92015\n",
      "f=5    k=7    p=1       w=distance      0.98167\n",
      "f=5    k=7    p=2       w=distance      0.96858\n",
      "f=5    k=7    p=100     w=distance      0.92276\n",
      "f=5    k=8    p=1       w=distance      0.97905\n",
      "f=5    k=8    p=2       w=distance      0.97120\n",
      "f=5    k=8    p=100     w=distance      0.91883\n",
      "f=5    k=9    p=1       w=distance      0.97774\n",
      "f=5    k=9    p=2       w=distance      0.97118\n",
      "f=5    k=9    p=100     w=distance      0.93324\n",
      "f=5    k=10   p=1       w=distance      0.98036\n",
      "f=5    k=10   p=2       w=distance      0.96988\n",
      "f=5    k=10   p=100     w=distance      0.92539\n",
      "f=5    k=11   p=1       w=distance      0.97251\n",
      "f=5    k=11   p=2       w=distance      0.96988\n",
      "f=5    k=11   p=100     w=distance      0.93456\n",
      "f=5    k=12   p=1       w=distance      0.97907\n",
      "f=5    k=12   p=2       w=distance      0.96596\n",
      "f=5    k=12   p=100     w=distance      0.93194\n",
      "f=5    k=13   p=1       w=distance      0.97381\n",
      "f=5    k=13   p=2       w=distance      0.96989\n",
      "f=5    k=13   p=100     w=distance      0.93326\n",
      "f=5    k=14   p=1       w=distance      0.97382\n",
      "f=5    k=14   p=2       w=distance      0.97251\n",
      "f=5    k=14   p=100     w=distance      0.93718\n",
      "f=10   k=1    p=1       w=uniform       0.94823\n",
      "f=10   k=1    p=2       w=uniform       0.93367\n",
      "f=10   k=1    p=100     w=uniform       0.90109\n",
      "f=10   k=2    p=1       w=uniform       0.97557\n",
      "f=10   k=2    p=2       w=uniform       0.96452\n",
      "f=10   k=2    p=100     w=uniform       0.94241\n",
      "f=10   k=3    p=1       w=uniform       0.98314\n",
      "f=10   k=3    p=2       w=uniform       0.96451\n",
      "f=10   k=3    p=100     w=uniform       0.91796\n",
      "f=10   k=4    p=1       w=uniform       0.98255\n",
      "f=10   k=4    p=2       w=uniform       0.97789\n",
      "f=10   k=4    p=100     w=uniform       0.93367\n",
      "f=10   k=5    p=1       w=uniform       0.97790\n",
      "f=10   k=5    p=2       w=uniform       0.96801\n",
      "f=10   k=5    p=100     w=uniform       0.92204\n",
      "f=10   k=6    p=1       w=uniform       0.98371\n",
      "f=10   k=6    p=2       w=uniform       0.97847\n",
      "f=10   k=6    p=100     w=uniform       0.93659\n",
      "f=10   k=7    p=1       w=uniform       0.98023\n",
      "f=10   k=7    p=2       w=uniform       0.97091\n",
      "f=10   k=7    p=100     w=uniform       0.92785\n",
      "f=10   k=8    p=1       w=uniform       0.98545\n",
      "f=10   k=8    p=2       w=uniform       0.98138\n",
      "f=10   k=8    p=100     w=uniform       0.94240\n",
      "f=10   k=9    p=1       w=uniform       0.98080\n",
      "f=10   k=9    p=2       w=uniform       0.97614\n",
      "f=10   k=9    p=100     w=uniform       0.93017\n",
      "f=10   k=10   p=1       w=uniform       0.97789\n",
      "f=10   k=10   p=2       w=uniform       0.98487\n",
      "f=10   k=10   p=100     w=uniform       0.94299\n",
      "f=10   k=11   p=1       w=uniform       0.97324\n",
      "f=10   k=11   p=2       w=uniform       0.97555\n",
      "f=10   k=11   p=100     w=uniform       0.93659\n",
      "f=10   k=12   p=1       w=uniform       0.97033\n",
      "f=10   k=12   p=2       w=uniform       0.97905\n",
      "f=10   k=12   p=100     w=uniform       0.94416\n",
      "f=10   k=13   p=1       w=uniform       0.97208\n",
      "f=10   k=13   p=2       w=uniform       0.96917\n",
      "f=10   k=13   p=100     w=uniform       0.93717\n",
      "f=10   k=14   p=1       w=uniform       0.97092\n",
      "f=10   k=14   p=2       w=uniform       0.97266\n",
      "f=10   k=14   p=100     w=uniform       0.93834\n",
      "f=10   k=1    p=1       w=distance      0.94823\n",
      "f=10   k=1    p=2       w=distance      0.93367\n",
      "f=10   k=1    p=100     w=distance      0.90109\n",
      "f=10   k=2    p=1       w=distance      0.94823\n",
      "f=10   k=2    p=2       w=distance      0.93367\n",
      "f=10   k=2    p=100     w=distance      0.90109\n",
      "f=10   k=3    p=1       w=distance      0.98314\n",
      "f=10   k=3    p=2       w=distance      0.96451\n",
      "f=10   k=3    p=100     w=distance      0.91796\n",
      "f=10   k=4    p=1       w=distance      0.97790\n",
      "f=10   k=4    p=2       w=distance      0.96684\n",
      "f=10   k=4    p=100     w=distance      0.91796\n",
      "f=10   k=5    p=1       w=distance      0.97790\n",
      "f=10   k=5    p=2       w=distance      0.96801\n",
      "f=10   k=5    p=100     w=distance      0.92204\n",
      "f=10   k=6    p=1       w=distance      0.97906\n",
      "f=10   k=6    p=2       w=distance      0.97033\n",
      "f=10   k=6    p=100     w=distance      0.92262\n",
      "f=10   k=7    p=1       w=distance      0.98023\n",
      "f=10   k=7    p=2       w=distance      0.97091\n",
      "f=10   k=7    p=100     w=distance      0.92785\n",
      "f=10   k=8    p=1       w=distance      0.98080\n",
      "f=10   k=8    p=2       w=distance      0.97091\n",
      "f=10   k=8    p=100     w=distance      0.92727\n",
      "f=10   k=9    p=1       w=distance      0.98080\n",
      "f=10   k=9    p=2       w=distance      0.97731\n",
      "f=10   k=9    p=100     w=distance      0.93017\n",
      "f=10   k=10   p=1       w=distance      0.97848\n",
      "f=10   k=10   p=2       w=distance      0.97382\n",
      "f=10   k=10   p=100     w=distance      0.92495\n",
      "f=10   k=11   p=1       w=distance      0.97324\n",
      "f=10   k=11   p=2       w=distance      0.97672\n",
      "f=10   k=11   p=100     w=distance      0.93659\n",
      "f=10   k=12   p=1       w=distance      0.97789\n",
      "f=10   k=12   p=2       w=distance      0.97091\n",
      "f=10   k=12   p=100     w=distance      0.92902\n",
      "f=10   k=13   p=1       w=distance      0.97498\n",
      "f=10   k=13   p=2       w=distance      0.97266\n",
      "f=10   k=13   p=100     w=distance      0.93717\n",
      "f=10   k=14   p=1       w=distance      0.97615\n",
      "f=10   k=14   p=2       w=distance      0.97208\n",
      "f=10   k=14   p=100     w=distance      0.93717\n",
      "f=20   k=1    p=1       w=uniform       0.94794\n",
      "f=20   k=1    p=2       w=uniform       0.93437\n",
      "f=20   k=1    p=100     w=uniform       0.90362\n",
      "f=20   k=2    p=1       w=uniform       0.97452\n",
      "f=20   k=2    p=2       w=uniform       0.96317\n",
      "f=20   k=2    p=100     w=uniform       0.94350\n",
      "f=20   k=3    p=1       w=uniform       0.98338\n",
      "f=20   k=3    p=2       w=uniform       0.96372\n",
      "f=20   k=3    p=100     w=uniform       0.92136\n",
      "f=20   k=4    p=1       w=uniform       0.98311\n",
      "f=20   k=4    p=2       w=uniform       0.97812\n",
      "f=20   k=4    p=100     w=uniform       0.93437\n",
      "f=20   k=5    p=1       w=uniform       0.97812\n",
      "f=20   k=5    p=2       w=uniform       0.96843\n",
      "f=20   k=5    p=100     w=uniform       0.92357\n",
      "f=20   k=6    p=1       w=uniform       0.98366\n",
      "f=20   k=6    p=2       w=uniform       0.97896\n",
      "f=20   k=6    p=100     w=uniform       0.93271\n",
      "f=20   k=7    p=1       w=uniform       0.98256\n",
      "f=20   k=7    p=2       w=uniform       0.97010\n",
      "f=20   k=7    p=100     w=uniform       0.92552\n",
      "f=20   k=8    p=1       w=uniform       0.98698\n",
      "f=20   k=8    p=2       w=uniform       0.98311\n",
      "f=20   k=8    p=100     w=uniform       0.94406\n",
      "f=20   k=9    p=1       w=uniform       0.98200\n",
      "f=20   k=9    p=2       w=uniform       0.97812\n",
      "f=20   k=9    p=100     w=uniform       0.93050\n",
      "f=20   k=10   p=1       w=uniform       0.98089\n",
      "f=20   k=10   p=2       w=uniform       0.98698\n",
      "f=20   k=10   p=100     w=uniform       0.94434\n",
      "f=20   k=11   p=1       w=uniform       0.97563\n",
      "f=20   k=11   p=2       w=uniform       0.97868\n",
      "f=20   k=11   p=100     w=uniform       0.93686\n",
      "f=20   k=12   p=1       w=uniform       0.97203\n",
      "f=20   k=12   p=2       w=uniform       0.98366\n",
      "f=20   k=12   p=100     w=uniform       0.94545\n",
      "f=20   k=13   p=1       w=uniform       0.97258\n",
      "f=20   k=13   p=2       w=uniform       0.97232\n",
      "f=20   k=13   p=100     w=uniform       0.94019\n",
      "f=20   k=14   p=1       w=uniform       0.96843\n",
      "f=20   k=14   p=2       w=uniform       0.97536\n",
      "f=20   k=14   p=100     w=uniform       0.94268\n",
      "f=20   k=1    p=1       w=distance      0.94794\n",
      "f=20   k=1    p=2       w=distance      0.93437\n",
      "f=20   k=1    p=100     w=distance      0.90362\n",
      "f=20   k=2    p=1       w=distance      0.94794\n",
      "f=20   k=2    p=2       w=distance      0.93437\n",
      "f=20   k=2    p=100     w=distance      0.90362\n",
      "f=20   k=3    p=1       w=distance      0.98338\n",
      "f=20   k=3    p=2       w=distance      0.96372\n",
      "f=20   k=3    p=100     w=distance      0.92136\n",
      "f=20   k=4    p=1       w=distance      0.97840\n",
      "f=20   k=4    p=2       w=distance      0.96815\n",
      "f=20   k=4    p=100     w=distance      0.91913\n",
      "f=20   k=5    p=1       w=distance      0.97812\n",
      "f=20   k=5    p=2       w=distance      0.96843\n",
      "f=20   k=5    p=100     w=distance      0.92357\n",
      "f=20   k=6    p=1       w=distance      0.97923\n",
      "f=20   k=6    p=2       w=distance      0.96954\n",
      "f=20   k=6    p=100     w=distance      0.92219\n",
      "f=20   k=7    p=1       w=distance      0.98256\n",
      "f=20   k=7    p=2       w=distance      0.97010\n",
      "f=20   k=7    p=100     w=distance      0.92552\n",
      "f=20   k=8    p=1       w=distance      0.97923\n",
      "f=20   k=8    p=2       w=distance      0.97065\n",
      "f=20   k=8    p=100     w=distance      0.92967\n",
      "f=20   k=9    p=1       w=distance      0.98200\n",
      "f=20   k=9    p=2       w=distance      0.97867\n",
      "f=20   k=9    p=100     w=distance      0.93050\n",
      "f=20   k=10   p=1       w=distance      0.97895\n",
      "f=20   k=10   p=2       w=distance      0.97425\n",
      "f=20   k=10   p=100     w=distance      0.92717\n",
      "f=20   k=11   p=1       w=distance      0.97563\n",
      "f=20   k=11   p=2       w=distance      0.97951\n",
      "f=20   k=11   p=100     w=distance      0.93686\n",
      "f=20   k=12   p=1       w=distance      0.97840\n",
      "f=20   k=12   p=2       w=distance      0.97009\n",
      "f=20   k=12   p=100     w=distance      0.92994\n",
      "f=20   k=13   p=1       w=distance      0.97674\n",
      "f=20   k=13   p=2       w=distance      0.97675\n",
      "f=20   k=13   p=100     w=distance      0.94019\n",
      "f=20   k=14   p=1       w=distance      0.97535\n",
      "f=20   k=14   p=2       w=distance      0.97009\n",
      "f=20   k=14   p=100     w=distance      0.93382\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.height', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "# Question 2a)\n",
    "bc_knn_results = pd.DataFrame()\n",
    "foldnum=0\n",
    "\n",
    "print len(bc_data)\n",
    "print len(bc_targets.values.ravel())\n",
    "\n",
    "for fold in [2, 3, 5, 10, 20]:\n",
    "    for train_total, test in cross_validation.KFold(len(bc_data), shuffle=True, n_folds=fold,\n",
    "                                               random_state=20160217):\n",
    "        foldnum+=1\n",
    "        size = len(train_total)\n",
    "        train = train_total[:2*(size / 3)]\n",
    "        validation = train_total[2*(size/3):]\n",
    "        \n",
    "        [bc_tr_data, bc_te_data, \n",
    "         bc_tr_targets, bc_te_targets] = folds_to_split(bc_data.values, bc_targets.values, train, validation)\n",
    "\n",
    "        # Give neighbors equal weight (uniform) or base weight on distance\n",
    "        for weight in ['uniform', 'distance']:\n",
    "            # Use 1, 2 or 15 neighbors to deteremine the class\n",
    "            for k in range(1,15):\n",
    "                #Use L1 (Manhattan), L2 (Euclidean), or L100 (approaching supremum distance)\n",
    "                for degree in [1, 2, 100]:\n",
    "                    knn = neighbors.KNeighborsClassifier(n_neighbors=k, p=degree, weights=weight)\n",
    "                    knn.fit(bc_tr_data.values, bc_tr_targets.values.ravel())\n",
    "                    bc_knn_results.loc[foldnum, 'f={:<5}k={:<5}p={:<8}w={:<10}'.format(fold, k, degree, weight)] = knn.score(bc_te_data.values,\n",
    "                                                                                                              bc_te_targets.values.ravel())\n",
    "print \"Results for different parameters of K-Nearest Neighbors\"\n",
    "print bc_knn_results.mean().apply(lambda x : '%0.5f' % x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569\n",
      "569\n",
      "Results for different parameters of K-Nearest Neighbors\n",
      "f=2    k=8    p=1       w=distance      0.95957\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Question 2b\n",
    "bc_knn_results = pd.DataFrame()\n",
    "foldnum=0\n",
    "\n",
    "print len(bc_data)\n",
    "print len(bc_targets.values.ravel())\n",
    "\n",
    "fold = 2\n",
    "k = 8\n",
    "degree = 1\n",
    "weight = 'distance'\n",
    "for train, test in cross_validation.KFold(len(bc_data), shuffle=True, n_folds=fold,\n",
    "                                       random_state=20160217):\n",
    "    foldnum+=1\n",
    "    [bc_tr_data, bc_te_data, \n",
    "    bc_tr_targets, bc_te_targets] = folds_to_split(bc_data.values, bc_targets.values, train, test)\n",
    "    \n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors=k, p=degree, weights=weight)\n",
    "    knn.fit(bc_tr_data.values, bc_tr_targets.values.ravel())\n",
    "    bc_knn_results.loc[foldnum, 'f={:<5}k={:<5}p={:<8}w={:<10}'.format(fold, k, degree, weight)] = knn.score(bc_te_data.values,\n",
    "                                                                                                          bc_te_targets.values.ravel())\n",
    "print \"Results for different parameters of K-Nearest Neighbors\"\n",
    "print bc_knn_results.mean().apply(lambda x : '%0.5f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit: Comparing K-D Trees and Ball Trees (10 points)\n",
    "One of the main issues with kNN is that as the size of the training set grows, the performance suffers. The implementations we've been using automatically use data structures such as K-D Trees and Ball Trees under the hood to speed things up, but it's useful to understand how much these algorithms help. In this question, you can explore this question first hand by generating ever-larger datasets until performance degrades, and then changing the number of features to see how this impacts the performance.\n",
    "1. Generate data using `make_classification` varying only the number of samples (`n_samples`), starting with 200 samples and doubling the number of samples at each iteration. Hold out 100 instances as your test set, and measure the running time of kNN with different underlying algorithms (iterate over the settings `brute_force`, `kd_tree`, and `ball_tree` for the `algorithm` parameter). When the running time reaches 1 second for the K-D Tree, stop generating larger datasets. Generate a (bar or line) plot of the running time of each of the three algorithms across the dataset sizes. Characterize the improvement you notice over the brute force method.\n",
    "\n",
    "2. Now freeze the number of samples to the largest size you reached in the previous question and continue to select 100 instances as your test set. Measure the running time of K-D Trees and Ball Trees as you vary the number of features generated from 10 to 1280. Make a plot of the running times of both methods for each of the feature sizes. How does the performance compare?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Answers Extra Credit </h1>\n",
    "<p>1. From the plot below, we can see that as we increase the sample size, the improvement in running time of the tree algorithms vs the brute force is significant. The brute force run time is O(DN) where D is number of features and N is sample size. The run time for the ball tree is O(Dlog(N)) and for the kd tree it's O(Dlog(N)) for small n, but can get upto O(DN) for large dataset. \n",
    "</p>\n",
    "\n",
    "<p>2. As features increase the performance of the ball tree is way better than the performance of the kd tree. This makes sense as the run time for kd trees is O(DN) when number of D features is large, while ball tree run time stays capped at O(Dlog(N))\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 200 algorithm: brute running time: 0.00543\n",
      "Size: 200 algorithm: ball_tree running time: 0.00495\n",
      "Size: 200 algorithm: kd_tree running time: 0.00338\n",
      "Size: 400 algorithm: brute running time: 0.00432\n",
      "Size: 400 algorithm: ball_tree running time: 0.00349\n",
      "Size: 400 algorithm: kd_tree running time: 0.00373\n",
      "Size: 800 algorithm: brute running time: 0.00511\n",
      "Size: 800 algorithm: ball_tree running time: 0.00508\n",
      "Size: 800 algorithm: kd_tree running time: 0.00476\n",
      "Size: 1600 algorithm: brute running time: 0.00892\n",
      "Size: 1600 algorithm: ball_tree running time: 0.00809\n",
      "Size: 1600 algorithm: kd_tree running time: 0.00730\n",
      "Size: 3200 algorithm: brute running time: 0.01655\n",
      "Size: 3200 algorithm: ball_tree running time: 0.01009\n",
      "Size: 3200 algorithm: kd_tree running time: 0.00909\n",
      "Size: 6400 algorithm: brute running time: 0.03297\n",
      "Size: 6400 algorithm: ball_tree running time: 0.01743\n",
      "Size: 6400 algorithm: kd_tree running time: 0.01649\n",
      "Size: 12800 algorithm: brute running time: 0.05966\n",
      "Size: 12800 algorithm: ball_tree running time: 0.03092\n",
      "Size: 12800 algorithm: kd_tree running time: 0.02641\n",
      "Size: 25600 algorithm: brute running time: 0.11452\n",
      "Size: 25600 algorithm: ball_tree running time: 0.06009\n",
      "Size: 25600 algorithm: kd_tree running time: 0.04944\n",
      "Size: 51200 algorithm: brute running time: 0.26243\n",
      "Size: 51200 algorithm: ball_tree running time: 0.12112\n",
      "Size: 51200 algorithm: kd_tree running time: 0.10520\n",
      "Size: 102400 algorithm: brute running time: 0.49167\n",
      "Size: 102400 algorithm: ball_tree running time: 0.24849\n",
      "Size: 102400 algorithm: kd_tree running time: 0.20822\n",
      "Size: 204800 algorithm: brute running time: 0.95777\n",
      "Size: 204800 algorithm: ball_tree running time: 0.44955\n",
      "Size: 204800 algorithm: kd_tree running time: 0.44916\n",
      "Size: 409600 algorithm: brute running time: 2.13033\n",
      "Size: 409600 algorithm: ball_tree running time: 0.94020\n",
      "Size: 409600 algorithm: kd_tree running time: 0.88598\n",
      "Size: 819200 algorithm: brute running time: 4.44605\n",
      "Size: 819200 algorithm: ball_tree running time: 1.99582\n",
      "Size: 819200 algorithm: kd_tree running time: 1.97064\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEACAYAAAB27puMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108cef410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "sample_size = 200\n",
    "brute_run_times = []\n",
    "ball_run_times = []\n",
    "kd_run_times = []\n",
    "sample_x = []\n",
    "c = 0\n",
    "\n",
    "while (c < 1):\n",
    "    sample_x.append(sample_size)\n",
    "    [data, targets] = datasets.make_classification(n_samples=sample_size, n_features=4,\n",
    "                                                    random_state=20160217)\n",
    "    \n",
    "    test = np.arange(0, 100, 1)\n",
    "    train = np.arange(100, sample_size, 1)\n",
    "\n",
    "    for algo in ['brute', 'ball_tree', 'kd_tree']:\n",
    "        a = time.clock()\n",
    "\n",
    "        foldnum+=1\n",
    "        [gen_tr_data, gen_te_data, \n",
    "         gen_tr_targets, gen_te_targets] = folds_to_split(data, targets, train, test)\n",
    "\n",
    "        knn = neighbors.KNeighborsClassifier(n_neighbors=5, algorithm = algo)\n",
    "        knn.fit(gen_te_data.values, gen_te_targets.values.ravel())\n",
    "        gen_knn_results.loc[foldnum, 'f={:<8}k={:<5}p={:<8}w={:<10}'.format(folds, k, degree, weight)] = knn.score(gen_tr_data.values,\n",
    "                                                                                                              gen_tr_targets.values.ravel())\n",
    "        b = time.clock()\n",
    "        c = (b - a)\n",
    "        time_ran = \"%.5f\" % c\n",
    "        print \"Size: \" + str(sample_size) + \" algorithm: \" + algo + \" running time: \" + str(time_ran)\n",
    "        if (algo == 'brute'):\n",
    "            brute_run_times.append(time_ran)\n",
    "        elif (algo =='ball_tree'):\n",
    "            ball_run_times.append(time_ran)\n",
    "        else:\n",
    "            kd_run_times.append(time_ran)\n",
    "    sample_size = sample_size * 2\n",
    "    \n",
    "# print sample_x\n",
    "# print brute_run_times\n",
    "# print ball_run_times\n",
    "# print kd_run_times\n",
    "\n",
    "plt.plot(sample_x, brute_run_times, \"r\", sample_x, ball_run_times, 'b', sample_x, kd_run_times, 'g')\n",
    "red_patch = mpatches.Patch(color='red', label='brute force')\n",
    "blue_patch = mpatches.Patch(color='blue', label='ball tree')\n",
    "green_patch = mpatches.Patch(color='green', label='kd tree')\n",
    "\n",
    "plt.legend(handles=[red_patch, blue_patch, green_patch], loc='upper left')\n",
    "\n",
    "plt.ylabel(\"run time in seconds\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200, 400, 800, 1600, 3200, 6400, 12800, 25600, 51200, 102400, 204800, 409600, 819200]\n"
     ]
    }
   ],
   "source": [
    "print sample_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 10 algorithm: ball_tree running time: 2.62227\n",
      "Size: 10 algorithm: kd_tree running time: 2.92251\n",
      "Size: 20 algorithm: ball_tree running time: 3.73325\n",
      "Size: 20 algorithm: kd_tree running time: 3.75784\n",
      "Size: 40 algorithm: ball_tree running time: 4.84724\n",
      "Size: 40 algorithm: kd_tree running time: 5.99769\n",
      "Size: 80 algorithm: ball_tree running time: 8.89866\n",
      "Size: 80 algorithm: kd_tree running time: 11.33307\n",
      "Size: 160 algorithm: ball_tree running time: 16.27572\n",
      "Size: 160 algorithm: kd_tree running time: 20.74353\n",
      "Size: 320 algorithm: ball_tree running time: 33.72186\n",
      "Size: 320 algorithm: kd_tree running time: 44.91873\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEACAYAAAC3adEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nESsMxhhjLvL/oSD65pOMs6gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108c88b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ball_run_times = []\n",
    "kd_run_times = []\n",
    "sample_x = []\n",
    "\n",
    "#10 to 1280\n",
    "sample_size = 819200\n",
    "feature_count = 10\n",
    "while feature_count <= 320:\n",
    "    sample_x.append(feature_count)\n",
    "    [data, targets] = datasets.make_classification(n_samples=sample_size, n_features=feature_count,\n",
    "                                                    random_state=20160217)\n",
    "    test = np.arange(0, 100, 1)\n",
    "    train = np.arange(100, sample_size, 1)\n",
    "\n",
    "    for algo in ['ball_tree', 'kd_tree']:\n",
    "        a = time.clock()\n",
    "\n",
    "        foldnum+=1\n",
    "        [gen_tr_data, gen_te_data, \n",
    "         gen_tr_targets, gen_te_targets] = folds_to_split(data, targets, train, test)\n",
    "\n",
    "        knn = neighbors.KNeighborsClassifier(n_neighbors=5, algorithm = algo)\n",
    "        knn.fit(gen_te_data.values, gen_te_targets.values.ravel())\n",
    "        gen_knn_results.loc[foldnum, 'f={:<8}k={:<5}p={:<8}w={:<10}'.format(folds, k, degree, weight)] = knn.score(gen_tr_data.values,\n",
    "                                                                                                              gen_tr_targets.values.ravel())\n",
    "        b = time.clock()\n",
    "        c = (b - a)\n",
    "        time_ran = \"%.5f\" % c\n",
    "        print \"Size: \" + str(feature_count) + \" algorithm: \" + algo + \" running time: \" + str(time_ran)\n",
    "        if (algo =='ball_tree'):\n",
    "            ball_run_times.append(time_ran)\n",
    "        else:\n",
    "            kd_run_times.append(time_ran)\n",
    "    \n",
    "    feature_count = feature_count * 2\n",
    "    \n",
    "# print sample_x\n",
    "# print ball_run_times\n",
    "# print kd_run_times\n",
    "\n",
    "plt.plot(sample_x, ball_run_times, 'b', sample_x, kd_run_times, 'g')\n",
    "blue_patch = mpatches.Patch(color='blue', label='ball tree')\n",
    "green_patch = mpatches.Patch(color='green', label='kd tree')\n",
    "\n",
    "plt.legend(handles=[blue_patch, green_patch], loc='upper left')\n",
    "\n",
    "plt.ylabel(\"run time in seconds\")\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
